{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "reserved-birmingham",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3 -u\n",
    "# Copyright (c) 2017-present, Facebook, Inc.\n",
    "# All rights reserved.\n",
    "#\n",
    "# This source code is licensed under the license found in the LICENSE file in\n",
    "# the root directory of this source tree.\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import csv\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import models\n",
    "from utils import progress_bar\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n",
    "# parser.add_argument('--lr', default=0.1, type=float, help='learning rate')\n",
    "# parser.add_argument('--resume', '-r', action='store_true',\n",
    "#                     help='resume from checkpoint')\n",
    "# parser.add_argument('--model', default=\"ResNet18\", type=str,\n",
    "#                     help='model type (default: ResNet18)')\n",
    "# parser.add_argument('--name', default='0', type=str, help='name of run')\n",
    "# parser.add_argument('--seed', default=0, type=int, help='random seed')\n",
    "# parser.add_argument('--batch-size', default=128, type=int, help='batch size')\n",
    "# parser.add_argument('--epoch', default=200, type=int,\n",
    "#                     help='total epochs to run')\n",
    "# parser.add_argument('--no-augment', dest='augment', action='store_false',\n",
    "#                     help='use standard augmentation (default: True)')\n",
    "# parser.add_argument('--decay', default=1e-4, type=float, help='weight decay')\n",
    "# parser.add_argument('--alpha', default=1., type=float,\n",
    "#                     help='mixup interpolation coefficient (default: 1)')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "params = {\n",
    "    \"lr\": .01,\n",
    "    \"resume\": False,\n",
    "    \"model\": \"ResNet18\",\n",
    "    \"name\": \"mixup-128-AdvsTrain-Eps0.45\",\n",
    "    \"seed\": 10,\n",
    "    \"batch_size\": 128,\n",
    "    \"decay\": 1e-4, \n",
    "    \"augment\": True,\n",
    "    \"epoch\": 200,\n",
    "#     \"no_augment\": False,\n",
    "    \"alpha\": 1.,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "junior-depression",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "if params[\"seed\"] != 0:\n",
    "    torch.manual_seed(params[\"seed\"])\n",
    "\n",
    "# Data\n",
    "print('==> Preparing data..')\n",
    "if params[\"augment\"]:\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                             (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "else:\n",
    "    print(\"no augmentation\")\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                             (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=False,\n",
    "                            transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                          batch_size=params[\"batch_size\"],\n",
    "                                          shuffle=True, num_workers=8)\n",
    "\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=False,\n",
    "                           transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100,\n",
    "                                         shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "disabled-finish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building model..\n",
      "3\n",
      "Using CUDA..\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "if params[\"resume\"]:\n",
    "    # Load checkpoint.\n",
    "    print('==> Resuming from checkpoint..')\n",
    "    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
    "    checkpoint = torch.load('./checkpoint/ckpt.t7' + params[\"name\"] + '_'\n",
    "                            + str(params[\"seed\"]), map_location='cpu')\n",
    "    \n",
    "    net = checkpoint['net']\n",
    "    best_acc = checkpoint['acc']\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    rng_state = checkpoint['rng_state']\n",
    "    torch.set_rng_state(rng_state)\n",
    "else:\n",
    "    print('==> Building model..')\n",
    "    net = models.__dict__[params[\"model\"]]()\n",
    "\n",
    "if not os.path.isdir('results'):\n",
    "    os.mkdir('results')\n",
    "logname = ('results/log_' + net.__class__.__name__ + '_' + params[\"name\"] + '_'\n",
    "           + str(params[\"seed\"]) + '.csv')\n",
    "\n",
    "if use_cuda:\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    net.to(f'cuda:{net.device_ids[0]}')\n",
    "    print(torch.cuda.device_count())\n",
    "    cudnn.benchmark = True\n",
    "    print('Using CUDA..')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=params[\"lr\"], momentum=0.9,\n",
    "                      weight_decay=params[\"decay\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "crazy-cooper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12,  3,  2,  1])"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3,4])\n",
    "b = a[[3,2,1,0]]\n",
    "b[0] = 12\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "innocent-court",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=1.0, use_cuda=True, advs_train=False, epsilon=.35):\n",
    "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    if use_cuda:\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "    \n",
    "\n",
    "    \n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    \n",
    "    \n",
    "    \n",
    "    if advs_train:\n",
    "        \n",
    "        x_b = x[index, :]\n",
    "        \n",
    "        x_b.requires_grad_(True)\n",
    "        x.requires_grad_(True)\n",
    "        \n",
    "        out_a = net(x)\n",
    "        loss_a = criterion(out_a, y_a)\n",
    "        optimizer.zero_grad()\n",
    "        loss_a.backward()\n",
    "        \n",
    "        err = torch.zeros_like(x)\n",
    "        with torch.no_grad():\n",
    "            err += epsilon * lam * x.grad.sign()\n",
    "\n",
    "        out_b = net(x_b)\n",
    "        loss_b = criterion(out_b, y_b)\n",
    "        optimizer.zero_grad()\n",
    "        loss_b.backward()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            err += epsilon * (1 - lam) * x_b.grad.sign()\n",
    "            \n",
    "        mixed_x += err\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "\n",
    "def train_mixup(epoch, erm=False, advs_train=False, epsilon=.35):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    reg_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        \n",
    "        if erm:\n",
    "            inputs, targets_a, targets_b, lam = mixup_data(inputs, targets,\n",
    "                                                           alpha=0, use_cuda=use_cuda, advs_train=advs_train)            \n",
    "        else:\n",
    "            inputs, targets_a, targets_b, lam = mixup_data(inputs, targets,\n",
    "                                                           params[\"alpha\"], use_cuda, \n",
    "                                                           advs_train=advs_train, epsilon=epsilon)\n",
    "        inputs, targets_a, targets_b = map(Variable, (inputs,\n",
    "                                                      targets_a, targets_b))\n",
    "        outputs = net(inputs)\n",
    "        loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (lam * predicted.eq(targets_a.data).cpu().sum().float()\n",
    "                    + (1 - lam) * predicted.eq(targets_b.data).cpu().sum().float())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        progress_bar(batch_idx, len(trainloader),\n",
    "                     'Loss: %.3f | Reg: %.5f | Acc: %.3f%% (%d/%d)'\n",
    "                     % (train_loss/(batch_idx+1), reg_loss/(batch_idx+1),\n",
    "                        100.*correct/total, correct, total))\n",
    "    return (train_loss/batch_idx, reg_loss/batch_idx, 100.*correct/total)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fgsm(x, y, eps):\n",
    "    \n",
    "        x.requires_grad_(True)\n",
    "        out = net(x)\n",
    "        loss = criterion(out, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            err = eps * lam * x.grad.sign()    \n",
    "            x_advs = x + err\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        inputs, targets = Variable(inputs, volatile=True), Variable(targets)\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets.data).cpu().sum()\n",
    "\n",
    "        progress_bar(batch_idx, len(testloader),\n",
    "                     'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                     % (test_loss/(batch_idx+1), 100.*correct/total,\n",
    "                        correct, total))\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        checkpoint(acc, epoch)\n",
    "\n",
    "        \n",
    "    return (test_loss/batch_idx, 100.*correct/total)\n",
    "\n",
    "\n",
    "def checkpoint(acc, epoch):\n",
    "    # Save checkpoint.\n",
    "    print('Saving..')\n",
    "    state = {\n",
    "        'net': net,\n",
    "        'acc': acc,\n",
    "        'epoch': epoch,\n",
    "        'rng_state': torch.get_rng_state()\n",
    "    }\n",
    "    if not os.path.isdir('checkpoint'):\n",
    "        os.mkdir('checkpoint')\n",
    "    torch.save(state, './checkpoint/ckpt.t7' + params[\"name\"] + '_'\n",
    "               + str(params[\"seed\"]))\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"decrease the learning rate at 100 and 150 epoch\"\"\"\n",
    "    lr = params[\"lr\"]\n",
    "    if epoch >= 100:\n",
    "        lr /= 10\n",
    "    if epoch >= 150:\n",
    "        lr /= 10\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "forced-navigation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      " [=====================================================================================>]  Step: 155ms | Tot: 58s482ms | Loss: 2.304 | Reg: 0.00000 | Acc: 11.587% (5793/50000 391/391 \n",
      " [===>..................................................................................]  Step: 37ms | Tot: 142ms | Loss: 2.124 | Acc: 28.000% (140/500 5/100 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-443-a2a30524e926>:105: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  inputs, targets = Variable(inputs, volatile=True), Variable(targets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [=====================================================================================>]  Step: 34ms | Tot: 3s636ms | Loss: 2.142 | Acc: 25.000% (2500/10000 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 1\n",
      " [=====================================================================================>]  Step: 155ms | Tot: 58s754ms | Loss: 2.270 | Reg: 0.00000 | Acc: 13.578% (6789/50000 391/391 \n",
      " [=====================================================================================>]  Step: 37ms | Tot: 3s614ms | Loss: 2.108 | Acc: 25.360% (2536/10000 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 2\n",
      " [=====================================================================================>]  Step: 148ms | Tot: 58s738ms | Loss: 2.252 | Reg: 0.00000 | Acc: 15.037% (7518/50000 391/391 \n",
      " [=====================================================================================>]  Step: 37ms | Tot: 3s595ms | Loss: 2.052 | Acc: 24.080% (2408/10000 100/100 \n",
      "\n",
      "Epoch: 3\n",
      " [=====================================================================================>]  Step: 150ms | Tot: 58s550ms | Loss: 2.199 | Reg: 0.00000 | Acc: 17.645% (8822/50000 391/391 \n",
      " [=====================================================================================>]  Step: 37ms | Tot: 3s621ms | Loss: 1.936 | Acc: 29.110% (2911/10000 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 4\n",
      " [=====================================================================================>]  Step: 147ms | Tot: 58s862ms | Loss: 2.100 | Reg: 0.00000 | Acc: 22.806% (11403/50000 391/391 \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s613ms | Loss: 2.329 | Acc: 20.550% (2055/10000 100/100 ...............]  Step: 37ms | Tot: 201ms | Loss: 2.353 | Acc: 19.429% (136/700 7/100 \n",
      "\n",
      "Epoch: 5\n",
      " [=====================================================================================>]  Step: 148ms | Tot: 58s565ms | Loss: 2.013 | Reg: 0.00000 | Acc: 26.956% (13478/50000 391/391 \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s650ms | Loss: 2.160 | Acc: 22.530% (2253/10000 100/100 \n",
      "\n",
      "Epoch: 6\n",
      " [=====================================================================================>]  Step: 148ms | Tot: 58s528ms | Loss: 1.906 | Reg: 0.00000 | Acc: 32.220% (16109/50000 391/391 \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s630ms | Loss: 1.834 | Acc: 33.650% (3365/10000 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 7\n",
      " [=====================================================================================>]  Step: 152ms | Tot: 58s624ms | Loss: 1.810 | Reg: 0.00000 | Acc: 37.348% (18674/50000 391/391 \n",
      " [=====================================================================================>]  Step: 37ms | Tot: 3s608ms | Loss: 1.651 | Acc: 40.270% (4027/10000 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 8\n",
      " [=====================================================================================>]  Step: 153ms | Tot: 58s511ms | Loss: 1.748 | Reg: 0.00000 | Acc: 40.455% (20227/50000 391/391 \n",
      " [=====================================================================================>]  Step: 35ms | Tot: 3s605ms | Loss: 1.559 | Acc: 45.140% (4514/10000 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 9\n",
      " [=====================================================================================>]  Step: 151ms | Tot: 58s525ms | Loss: 1.656 | Reg: 0.00000 | Acc: 45.152% (22575/50000 391/391 \n",
      " [=====================================================================================>]  Step: 35ms | Tot: 3s589ms | Loss: 1.248 | Acc: 58.160% (5816/10000 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 10\n",
      " [=====================================================================================>]  Step: 150ms | Tot: 58s448ms | Loss: 1.545 | Reg: 0.00000 | Acc: 50.424% (25211/50000 391/391 \n",
      " [=====================================================================================>]  Step: 37ms | Tot: 3s545ms | Loss: 1.458 | Acc: 49.770% (4977/10000 100/100 ..........]  Step: 31ms | Tot: 2s734ms | Loss: 1.456 | Acc: 49.805% (3835/7700 77/100 81/100 87/100 \n",
      "\n",
      "Epoch: 11\n",
      " [=====================================================================================>]  Step: 151ms | Tot: 58s413ms | Loss: 1.512 | Reg: 0.00000 | Acc: 52.692% (26345/50000 391/391 \n",
      " [=====================================================================================>]  Step: 35ms | Tot: 3s604ms | Loss: 1.069 | Acc: 63.980% (6398/10000 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 12\n",
      " [=====================================================================================>]  Step: 148ms | Tot: 58s405ms | Loss: 1.442 | Reg: 0.00000 | Acc: 56.050% (28024/50000 391/391 \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s603ms | Loss: 1.282 | Acc: 55.820% (5582/10000 100/100 \n",
      "\n",
      "Epoch: 13\n",
      " [=====================================================================================>]  Step: 159ms | Tot: 59s334ms | Loss: 1.404 | Reg: 0.00000 | Acc: 57.503% (28751/50000 391/391 \n",
      " [=====================================================================================>]  Step: 42ms | Tot: 3s717ms | Loss: 1.421 | Acc: 54.200% (5420/10000 100/100 0 .......]  Step: 44ms | Tot: 849ms | Loss: 1.414 | Acc: 55.000% (1375/2500 25/100 ............]  Step: 41ms | Tot: 2s148ms | Loss: 1.422 | Acc: 54.167% (3250/6000 60/100 =======================================>..................................]  Step: 42ms | Tot: 2s190ms | Loss: 1.422 | Acc: 54.131% (3302/6100 61/100 .........]  Step: 42ms | Tot: 2s269ms | Loss: 1.418 | Acc: 54.190% (3414/6300 63/10 70/100 ..........]  Step: 43ms | Tot: 2s743ms | Loss: 1.424 | Acc: 54.093% (4057/7500 75/100 ...............]  Step: 39ms | Tot: 2s783ms | Loss: 1.422 | Acc: 54.158% (4116/7600 76/100 ]  Step: 41ms | Tot: 3s313ms | Loss: 1.423 | Acc: 54.111% (4870/9000 90/100 ============================================>......]  Step: 41ms | Tot: 3s433ms | Loss: 1.420 | Acc: 54.194% (5040/9300 93/100 ============================================================>.....]  Step: 42ms | Tot: 3s515ms | Loss: 1.421 | Acc: 54.168% (5146/9500 95/100 \n",
      "\n",
      "Epoch: 14\n",
      " [=====================================================================================>]  Step: 154ms | Tot: 1m907ms | Loss: 1.370 | Reg: 0.00000 | Acc: 58.741% (29370/50000 391/391  \n",
      " [=====================================================================================>]  Step: 41ms | Tot: 3s593ms | Loss: 1.293 | Acc: 56.300% (5630/10000 100/100 ===>..........................................................................]  Step: 37ms | Tot: 426ms | Loss: 1.279 | Acc: 56.786% (795/1400 14/100 15/100 .........]  Step: 43ms | Tot: 502ms | Loss: 1.297 | Acc: 56.375% (902/1600 16/100 .....]  Step: 29ms | Tot: 1s519ms | Loss: 1.296 | Acc: 56.136% (2470/4400 44/100 49/100 .....]  Step: 30ms | Tot: 1s719ms | Loss: 1.295 | Acc: 56.100% (2805/5000 50/100 ...]  Step: 36ms | Tot: 1s918ms | Loss: 1.294 | Acc: 56.182% (3090/5500 55/100 .............]  Step: 41ms | Tot: 1s959ms | Loss: 1.296 | Acc: 56.054% (3139/5600 56/100 67/100 ========================================================>........................]  Step: 37ms | Tot: 2s537ms | Loss: 1.298 | Acc: 56.208% (4047/7200 72/100 .........]  Step: 39ms | Tot: 2s611ms | Loss: 1.296 | Acc: 56.189% (4158/7400 74/100 ]  Step: 39ms | Tot: 2s849ms | Loss: 1.294 | Acc: 56.284% (4559/8100 81/100 .....]  Step: 31ms | Tot: 2s880ms | Loss: 1.294 | Acc: 56.293% (4616/8200 82/100 \n",
      "\n",
      "Epoch: 15\n",
      " [=====================================================================================>]  Step: 162ms | Tot: 1m674ms | Loss: 1.306 | Reg: 0.00000 | Acc: 61.268% (30633/50000 391/391  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [=====================================================================================>]  Step: 41ms | Tot: 3s649ms | Loss: 1.380 | Acc: 52.320% (5232/1000 99/100 ]  Step: 38ms | Tot: 994ms | Loss: 1.396 | Acc: 52.379% (1519/2900 29/100 31/100 ................]  Step: 45ms | Tot: 1s552ms | Loss: 1.388 | Acc: 52.886% (2327/4400 44/100 53/100 ...................]  Step: 33ms | Tot: 2s132ms | Loss: 1.392 | Acc: 52.583% (3155/6000 60/100 ....]  Step: 33ms | Tot: 2s202ms | Loss: 1.387 | Acc: 52.629% (3263/6200 62/100 .....]  Step: 33ms | Tot: 2s235ms | Loss: 1.387 | Acc: 52.587% (3313/6300 63/100 =================================>..............................]  Step: 35ms | Tot: 2s335ms | Loss: 1.384 | Acc: 52.545% (3468/6600 66/100 ======================>.............]  Step: 41ms | Tot: 3s44ms | Loss: 1.381 | Acc: 52.494% (4462/8500 85/100 ...]  Step: 39ms | Tot: 3s83ms | Loss: 1.380 | Acc: 52.500% (4515/8600 86/100 .......]  Step: 42ms | Tot: 3s204ms | Loss: 1.381 | Acc: 52.404% (4664/8900 89/100 ===================>...]  Step: 39ms | Tot: 3s528ms | Loss: 1.381 | Acc: 52.330% (5076/9700 97/100 100/100 \n",
      "\n",
      "Epoch: 16\n",
      " [=====================================================================================>]  Step: 148ms | Tot: 1m482ms | Loss: 1.321 | Reg: 0.00000 | Acc: 60.231% (30115/50000 391/391  \n",
      " [=====================================================================================>]  Step: 40ms | Tot: 3s651ms | Loss: 1.265 | Acc: 58.000% (5800/10000 100/100 /100 47/100 59/10 91/100 \n",
      "\n",
      "Epoch: 17\n",
      " [=====================================================================================>]  Step: 165ms | Tot: 1m731ms | Loss: 1.298 | Reg: 0.00000 | Acc: 60.943% (30471/50000 391/391  \n",
      " [=====================================================================================>]  Step: 41ms | Tot: 3s590ms | Loss: 1.047 | Acc: 65.130% (6513/10000 100/100 00 .........................................................]  Step: 40ms | Tot: 835ms | Loss: 1.052 | Acc: 64.720% (1618/2500 25/100 91/100 =======================================================>.....]  Step: 38ms | Tot: 3s388ms | Loss: 1.047 | Acc: 65.147% (6189/9500 95/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 18\n",
      " [=====================================================================================>]  Step: 162ms | Tot: 1m483ms | Loss: 1.267 | Reg: 0.00000 | Acc: 62.510% (31255/50000 391/391  \n",
      " [=====================================================================================>]  Step: 34ms | Tot: 3s679ms | Loss: 1.038 | Acc: 65.550% (6555/10000 100/100 .]  Step: 42ms | Tot: 226ms | Loss: 1.000 | Acc: 67.429% (472/700 7/100 16/100 ....]  Step: 39ms | Tot: 572ms | Loss: 1.026 | Acc: 65.882% (1120/1700 17/100 ...........]  Step: 33ms | Tot: 634ms | Loss: 1.028 | Acc: 65.526% (1245/1900 19/100 ................................]  Step: 37ms | Tot: 671ms | Loss: 1.036 | Acc: 65.150% (1303/2000 20/100 ..................................................................]  Step: 31ms | Tot: 703ms | Loss: 1.038 | Acc: 64.952% (1364/2100 21/100 =============>...................................................................]  Step: 29ms | Tot: 732ms | Loss: 1.037 | Acc: 64.818% (1426/22 22/10 24/100 ........................................................]  Step: 33ms | Tot: 835ms | Loss: 1.037 | Acc: 65.160% (1629/25 25/100 .......................]  Step: 38ms | Tot: 874ms | Loss: 1.045 | Acc: 65.000% (1690/2600 26/100 =========================>............................................................]  Step: 27ms | Tot: 1s39ms | Loss: 1.039 | Acc: 65.387% (2027/3100 31/100 ==================>..........................................................]  Step: 41ms | Tot: 1s115ms | Loss: 1.036 | Acc: 65.394% (2158/3300 33/100 ...........]  Step: 40ms | Tot: 2s97ms | Loss: 1.043 | Acc: 65.288% (3852/5900 59/100 ==================>...............................]  Step: 40ms | Tot: 2s296ms | Loss: 1.039 | Acc: 65.484% (4191/6400 64/100 ......]  Step: 41ms | Tot: 2s338ms | Loss: 1.041 | Acc: 65.462% (4255/6500 65/100 77/100 ==============================================================>......]  Step: 37ms | Tot: 3s418ms | Loss: 1.039 | Acc: 65.505% (6092/9300 93/100 ===============================================>....]  Step: 42ms | Tot: 3s536ms | Loss: 1.037 | Acc: 65.615% (6299/9600 96/100 ]  Step: 40ms | Tot: 3s576ms | Loss: 1.036 | Acc: 65.619% (6365/9700 97/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 19\n",
      " [=====================================================================================>]  Step: 152ms | Tot: 1m494ms | Loss: 1.279 | Reg: 0.00000 | Acc: 62.074% (31037/50000 391/391  \n",
      " [=====================================================================================>]  Step: 41ms | Tot: 3s631ms | Loss: 1.022 | Acc: 65.720% (6572/1000099/100 ===========================================================>........................]  Step: 36ms | Tot: 2s582ms | Loss: 1.031 | Acc: 65.708% (4731/7200 72/100 ......]  Step: 27ms | Tot: 2s817ms | Loss: 1.025 | Acc: 65.785% (5197/7900 79/100 80/100 ==============>................]  Step: 41ms | Tot: 2s927ms | Loss: 1.023 | Acc: 65.878% (5402/8200 82/100 ======================================>...............]  Step: 33ms | Tot: 2s960ms | Loss: 1.021 | Acc: 65.892% (5469/8300 83/100 ......]  Step: 40ms | Tot: 3s314ms | Loss: 1.023 | Acc: 65.641% (6039/9200 92/100 =====>...]  Step: 45ms | Tot: 3s515ms | Loss: 1.022 | Acc: 65.773% (6380/9700 97/10 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 20\n",
      " [=====================================================================================>]  Step: 158ms | Tot: 1m838ms | Loss: 1.282 | Reg: 0.00000 | Acc: 61.524% (30761/50000 391/391  \n",
      " [=====================================================================================>]  Step: 44ms | Tot: 3s687ms | Loss: 1.175 | Acc: 60.940% (6094/10000 100/100 10 90/100 \n",
      "\n",
      "Epoch: 21\n",
      " [=====================================================================================>]  Step: 162ms | Tot: 1m920ms | Loss: 1.239 | Reg: 0.00000 | Acc: 63.176% (31588/50000 391/391  \n",
      " [=====================================================================================>]  Step: 38ms | Tot: 3s685ms | Loss: 1.320 | Acc: 56.960% (5696/10000 100/100 .........]  Step: 36ms | Tot: 201ms | Loss: 1.250 | Acc: 58.714% (411/700 7/100 ..................................................]  Step: 33ms | Tot: 878ms | Loss: 1.328 | Acc: 56.654% (1473/2600 26/100 ............]  Step: 31ms | Tot: 909ms | Loss: 1.323 | Acc: 56.778% (1533/2700 27/100 .....................................]  Step: 44ms | Tot: 985ms | Loss: 1.324 | Acc: 56.793% (1647/2900 29/100 ...............................]  Step: 42ms | Tot: 1s613ms | Loss: 1.316 | Acc: 57.200% (2574/4500 45/100 ............]  Step: 31ms | Tot: 2s198ms | Loss: 1.337 | Acc: 56.738% (3461/6100 61/100 ..]  Step: 30ms | Tot: 2s229ms | Loss: 1.336 | Acc: 56.758% (3519/6200 62/100 ==========>........]  Step: 39ms | Tot: 3s333ms | Loss: 1.323 | Acc: 56.967% (5184/9100 91/100 =======>.......]  Step: 40ms | Tot: 3s374ms | Loss: 1.322 | Acc: 57.022% (5246/9200 92/100 99/100 \n",
      "\n",
      "Epoch: 22\n",
      " [=====================================================================================>]  Step: 157ms | Tot: 1m302ms | Loss: 1.259 | Reg: 0.00000 | Acc: 62.803% (31401/50000 391/391  \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s589ms | Loss: 0.980 | Acc: 66.990% (6699/10000 100/100 ==========================================>........................]  Step: 32ms | Tot: 2s561ms | Loss: 0.988 | Acc: 66.764% (4807/7200 72/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 23\n",
      " [=====================================================================================>]  Step: 156ms | Tot: 59s53ms | Loss: 1.261 | Reg: 0.00000 | Acc: 62.309% (31154/50000 391/391  \n",
      " [=====================================================================================>]  Step: 37ms | Tot: 3s670ms | Loss: 0.960 | Acc: 67.890% (6789/10000 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 24\n",
      " [=====================================================================================>]  Step: 153ms | Tot: 59s71ms | Loss: 1.239 | Reg: 0.00000 | Acc: 63.093% (31546/50000 391/391  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [=====================================================================================>]  Step: 34ms | Tot: 3s635ms | Loss: 1.032 | Acc: 65.830% (6583/10000 100/100 \n",
      "\n",
      "Epoch: 25\n",
      " [=====================================================================================>]  Step: 151ms | Tot: 59s49ms | Loss: 1.222 | Reg: 0.00000 | Acc: 63.711% (31855/50000 391/391  \n",
      " [=====================================================================================>]  Step: 39ms | Tot: 3s870ms | Loss: 0.997 | Acc: 67.410% (6741/10000 100/100 \n",
      "\n",
      "Epoch: 26\n",
      " [=====================================================================================>]  Step: 149ms | Tot: 59s51ms | Loss: 1.197 | Reg: 0.00000 | Acc: 64.907% (32453/50000 391/391  \n",
      " [=====================================================================================>]  Step: 38ms | Tot: 3s643ms | Loss: 0.886 | Acc: 70.740% (7074/10000 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 27\n",
      " [=====================================================================================>]  Step: 151ms | Tot: 59s21ms | Loss: 1.230 | Reg: 0.00000 | Acc: 63.787% (31893/50000 391/391  \n",
      " [=====================================================================================>]  Step: 32ms | Tot: 3s656ms | Loss: 0.983 | Acc: 67.370% (6737/10000 100/100 \n",
      "\n",
      "Epoch: 28\n",
      " [=====================================================================================>]  Step: 151ms | Tot: 59s60ms | Loss: 1.199 | Reg: 0.00000 | Acc: 65.082% (32541/50000 391/391  \n",
      " [=====================================================================================>]  Step: 39ms | Tot: 3s657ms | Loss: 0.875 | Acc: 71.430% (7143/10000 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 29\n",
      " [=====================================================================================>]  Step: 154ms | Tot: 59s724ms | Loss: 1.214 | Reg: 0.00000 | Acc: 64.264% (32132/50000 391/391 \n",
      " [=====================================================================================>]  Step: 37ms | Tot: 3s702ms | Loss: 0.888 | Acc: 71.120% (7112/10000 100/100 \n",
      "\n",
      "Epoch: 30\n",
      " [=====================================================================================>]  Step: 153ms | Tot: 59s472ms | Loss: 1.189 | Reg: 0.00000 | Acc: 65.120% (32560/50000 391/391 \n",
      " [=====================================================================================>]  Step: 37ms | Tot: 3s651ms | Loss: 0.958 | Acc: 68.550% (6855/10000 100/100 ........................]  Step: 39ms | Tot: 201ms | Loss: 0.928 | Acc: 70.286% (492/700 7/100 \n",
      "\n",
      "Epoch: 31\n",
      " [=====================================================================================>]  Step: 153ms | Tot: 59s600ms | Loss: 1.192 | Reg: 0.00000 | Acc: 64.309% (32154/50000 391/391 \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s679ms | Loss: 0.812 | Acc: 74.000% (7400/10000 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 32\n",
      " [=====================================================================================>]  Step: 152ms | Tot: 1m353ms | Loss: 1.171 | Reg: 0.00000 | Acc: 65.652% (32825/50000 391/391  \n",
      " [=====================================================================================>]  Step: 35ms | Tot: 3s968ms | Loss: 0.856 | Acc: 71.570% (7157/10000 100/100 /100 ...]  Step: 46ms | Tot: 2s271ms | Loss: 0.867 | Acc: 70.869% (4323/6100 61/100 64/100 ]  Step: 39ms | Tot: 3s307ms | Loss: 0.864 | Acc: 71.182% (6264/8800 88/100 \n",
      "\n",
      "Epoch: 33\n",
      " [=====================================================================================>]  Step: 152ms | Tot: 1m485ms | Loss: 1.161 | Reg: 0.00000 | Acc: 65.808% (32904/50000 391/391  \n",
      " [=====================================================================================>]  Step: 37ms | Tot: 3s690ms | Loss: 0.955 | Acc: 68.350% (6835/10000 100/100 ..........]  Step: 44ms | Tot: 1s339ms | Loss: 0.966 | Acc: 68.108% (2520/3700 37/100 \n",
      "\n",
      "Epoch: 34\n",
      " [=====================================================================================>]  Step: 154ms | Tot: 1m550ms | Loss: 1.184 | Reg: 0.00000 | Acc: 65.341% (32670/50000 391/391  \n",
      " [=====================================================================================>]  Step: 37ms | Tot: 3s756ms | Loss: 0.927 | Acc: 70.910% (7091/10000 100/100 100 89/100 \n",
      "\n",
      "Epoch: 35\n",
      " [=====================================================================================>]  Step: 161ms | Tot: 1m543ms | Loss: 1.218 | Reg: 0.00000 | Acc: 63.613% (31806/50000 391/391  \n",
      " [=====================================================================================>]  Step: 38ms | Tot: 3s755ms | Loss: 0.907 | Acc: 70.830% (7083/10000 100/100 ......................]  Step: 39ms | Tot: 372ms | Loss: 0.892 | Acc: 71.727% (789/1100 11/100 \n",
      "\n",
      "Epoch: 36\n",
      " [=====================================================================================>]  Step: 152ms | Tot: 1m680ms | Loss: 1.177 | Reg: 0.00000 | Acc: 65.356% (32677/50000 391/391  \n",
      " [=====================================================================================>]  Step: 42ms | Tot: 3s713ms | Loss: 0.899 | Acc: 71.240% (7124/10000 100/100 \n",
      "\n",
      "Epoch: 37\n",
      " [=====================================================================================>]  Step: 154ms | Tot: 1m493ms | Loss: 1.165 | Reg: 0.00000 | Acc: 65.596% (32797/50000 391/391  \n",
      " [=====================================================================================>]  Step: 39ms | Tot: 3s712ms | Loss: 0.814 | Acc: 73.640% (7364/10000 100/100 10 51/10 59/100 66/100 ===========================================================================>.....]  Step: 40ms | Tot: 3s510ms | Loss: 0.816 | Acc: 73.558% (6988/9500 95/100 98/100 \n",
      "\n",
      "Epoch: 38\n",
      " [=====================================================================================>]  Step: 153ms | Tot: 59s905ms | Loss: 1.174 | Reg: 0.00000 | Acc: 65.286% (32643/50000 391/391 \n",
      " [=====================================================================================>]  Step: 37ms | Tot: 3s684ms | Loss: 0.790 | Acc: 75.360% (7536/10000 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 39\n",
      " [=====================================================================================>]  Step: 152ms | Tot: 59s882ms | Loss: 1.134 | Reg: 0.00000 | Acc: 67.348% (33673/50000 391/391 \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s694ms | Loss: 0.826 | Acc: 74.870% (7487/10000 100/100 \n",
      "\n",
      "Epoch: 40\n",
      " [=====================================================================================>]  Step: 156ms | Tot: 59s912ms | Loss: 1.167 | Reg: 0.00000 | Acc: 65.699% (32849/50000 391/391 \n",
      " [=====================================================================================>]  Step: 35ms | Tot: 3s697ms | Loss: 0.892 | Acc: 71.680% (7168/10000 100/100 \n",
      "\n",
      "Epoch: 41\n",
      " [=====================================================================================>]  Step: 156ms | Tot: 59s317ms | Loss: 1.119 | Reg: 0.00000 | Acc: 67.750% (33875/50000 391/391 \n",
      " [=====================================================================================>]  Step: 35ms | Tot: 3s609ms | Loss: 0.923 | Acc: 69.810% (6981/10000 100/100 0 \n",
      "\n",
      "Epoch: 42\n",
      " [=====================================================================================>]  Step: 150ms | Tot: 58s476ms | Loss: 1.129 | Reg: 0.00000 | Acc: 67.033% (33516/50000 391/391 \n",
      " [=====================================================================================>]  Step: 35ms | Tot: 3s613ms | Loss: 0.998 | Acc: 68.410% (6841/10000 100/100 \n",
      "\n",
      "Epoch: 43\n",
      " [=====================================================================================>]  Step: 154ms | Tot: 58s550ms | Loss: 1.156 | Reg: 0.00000 | Acc: 66.401% (33200/50000 391/391 \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s639ms | Loss: 0.826 | Acc: 75.290% (7529/10000 100/100 \n",
      "\n",
      "Epoch: 44\n",
      " [=====================================================================================>]  Step: 149ms | Tot: 58s418ms | Loss: 1.172 | Reg: 0.00000 | Acc: 65.270% (32635/50000 391/391 \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s600ms | Loss: 0.812 | Acc: 74.420% (7442/10000 100/100 \n",
      "\n",
      "Epoch: 45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [=====================================================================================>]  Step: 151ms | Tot: 58s476ms | Loss: 1.139 | Reg: 0.00000 | Acc: 66.829% (33414/50000 391/391 \n",
      " [=====================================================================================>]  Step: 35ms | Tot: 3s599ms | Loss: 0.783 | Acc: 75.440% (7544/10000 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 46\n",
      " [=====================================================================================>]  Step: 150ms | Tot: 58s738ms | Loss: 1.116 | Reg: 0.00000 | Acc: 67.703% (33851/50000 391/391 \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s669ms | Loss: 0.768 | Acc: 75.790% (7579/10000 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 47\n",
      " [=====================================================================================>]  Step: 168ms | Tot: 1m45ms | Loss: 1.131 | Reg: 0.00000 | Acc: 66.915% (33457/50000 391/391 1 \n",
      " [=====================================================================================>]  Step: 40ms | Tot: 3s890ms | Loss: 0.703 | Acc: 78.590% (7859/10000 100/100 ..........................................]  Step: 38ms | Tot: 1s198ms | Loss: 0.699 | Acc: 78.471% (2668/3400 34/100 51/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 48\n",
      " [=====================================================================================>]  Step: 159ms | Tot: 1m655ms | Loss: 1.119 | Reg: 0.00000 | Acc: 67.669% (33834/50000 391/391  \n",
      " [=====================================================================================>]  Step: 44ms | Tot: 3s630ms | Loss: 0.754 | Acc: 77.170% (7717/10000 100/100  ......]  Step: 43ms | Tot: 1s610ms | Loss: 0.747 | Acc: 77.844% (3503/4500 45/100 =======================================================================>..............]  Step: 29ms | Tot: 3s25ms | Loss: 0.758 | Acc: 77.143% (6480/8400 84/100 =================>........]  Step: 41ms | Tot: 3s297ms | Loss: 0.756 | Acc: 77.165% (7022/9100 91/100 \n",
      "\n",
      "Epoch: 49\n",
      " [=====================================================================================>]  Step: 152ms | Tot: 1m302ms | Loss: 1.131 | Reg: 0.00000 | Acc: 66.893% (33446/50000 391/391  \n",
      " [====================================================================================>.]  Step: 39ms | Tot: 3s591ms | Loss: 0.799 | Acc: 74.434% (7369/9900 99/100 ..]  Step: 33ms | Tot: 338ms | Loss: 0.803 | Acc: 75.000% (825/1100 11/100 ..........................]  Step: 36ms | Tot: 375ms | Loss: 0.796 | Acc: 75.250% (903/1200 12/100 ..................]  Step: 40ms | Tot: 964ms | Loss: 0.814 | Acc: 74.143% (2076/2800 28/100 ..........]  Step: 46ms | Tot: 1s371ms | Loss: 0.805 | Acc: 74.333% (2899/3900 39/100 ...]  Step: 40ms | Tot: 1s411ms | Loss: 0.805 | Acc: 74.300% (2972/4000 40/100 ===========>.................................................]  Step: 39ms | Tot: 1s526ms | Loss: 0.801 | Acc: 74.558% (3206/4300 43/100 .......]  Step: 32ms | Tot: 2s611ms | Loss: 0.809 | Acc: 74.178% (5415/7300 73/100 =========>.....]  Step: 44ms | Tot: 3s434ms | Loss: 0.801 | Acc: 74.316% (7060/9500 95/100 ===========>]  Step: 41ms | Tot: 3s632ms | Loss: 0.799 | Acc: 74.450% (7445/10000 100/100 \n",
      "\n",
      "Epoch: 50\n",
      " [=====================================================================================>]  Step: 154ms | Tot: 1m133ms | Loss: 1.118 | Reg: 0.00000 | Acc: 67.788% (33893/50000 391/391  \n",
      " [=====================================================================================>]  Step: 33ms | Tot: 3s565ms | Loss: 0.816 | Acc: 73.550% (7355/10000 100/100 .............]  Step: 39ms | Tot: 286ms | Loss: 0.812 | Acc: 74.222% (668/900 9/100 41/100 59/100 ..]  Step: 41ms | Tot: 2s168ms | Loss: 0.825 | Acc: 73.131% (4461/6100 61/100 ============================================================>..................]  Step: 29ms | Tot: 2s803ms | Loss: 0.821 | Acc: 73.253% (5787/7900 79/100 \n",
      "\n",
      "Epoch: 51\n",
      " [=====================================================================================>]  Step: 148ms | Tot: 58s600ms | Loss: 1.079 | Reg: 0.00000 | Acc: 68.991% (34495/50000 391/391 \n",
      " [=====================================================================================>]  Step: 37ms | Tot: 3s505ms | Loss: 0.737 | Acc: 77.490% (7749/10000 100/100 0 ................................]  Step: 33ms | Tot: 1s584ms | Loss: 0.749 | Acc: 76.870% (3536/4600 46/100 ...............................]  Step: 38ms | Tot: 1s622ms | Loss: 0.749 | Acc: 76.894% (3614/4700 47/10 52/100 58/100 63/100 ===========================>.............................]  Step: 26ms | Tot: 2s317ms | Loss: 0.744 | Acc: 77.045% (5162/6700 67/10 82/100 ==================================================>...............]  Step: 41ms | Tot: 2s881ms | Loss: 0.742 | Acc: 77.361% (6421/8300 83/100 \n",
      "\n",
      "Epoch: 52\n",
      " [=====================================================================================>]  Step: 169ms | Tot: 58s505ms | Loss: 1.123 | Reg: 0.00000 | Acc: 67.570% (33785/50000 391/391 \n",
      " [=====================================================================================>]  Step: 38ms | Tot: 3s554ms | Loss: 0.800 | Acc: 75.590% (7559/10000 100/100 0 .........................]  Step: 29ms | Tot: 1s33ms | Loss: 0.812 | Acc: 75.097% (2328/3100 31/10 37/100 ...]  Step: 35ms | Tot: 1s381ms | Loss: 0.810 | Acc: 75.075% (3003/4000 40/100 ..................]  Step: 42ms | Tot: 1s461ms | Loss: 0.810 | Acc: 75.071% (3153/4200 42/100 88/100 \n",
      "\n",
      "Epoch: 53\n",
      " [=====================================================================================>]  Step: 167ms | Tot: 59s571ms | Loss: 1.070 | Reg: 0.00000 | Acc: 69.276% (34638/50000 391/391 \n",
      " [=====================================================================================>]  Step: 39ms | Tot: 3s614ms | Loss: 0.679 | Acc: 79.820% (7982/10000 100/100 ..]  Step: 39ms | Tot: 321ms | Loss: 0.655 | Acc: 81.100% (811/1000 10/100 .....................]  Step: 34ms | Tot: 1s541ms | Loss: 0.681 | Acc: 80.091% (3524/4400 44/10 99/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 54\n",
      " [=====================================================================================>]  Step: 144ms | Tot: 58s944ms | Loss: 1.080 | Reg: 0.00000 | Acc: 68.623% (34311/50000 391/391 \n",
      " [====================================================================================>.]  Step: 40ms | Tot: 3s548ms | Loss: 0.737 | Acc: 77.333% (7656/9900 99/100  ......]  Step: 29ms | Tot: 286ms | Loss: 0.728 | Acc: 77.900% (779/1000 10/100 ....................]  Step: 31ms | Tot: 317ms | Loss: 0.733 | Acc: 77.636% (854/1100 11/10 15/10 63/100 =====================>]  Step: 43ms | Tot: 3s592ms | Loss: 0.736 | Acc: 77.380% (7738/10000 100/100 \n",
      "\n",
      "Epoch: 55\n",
      " [=====================================================================================>]  Step: 161ms | Tot: 58s844ms | Loss: 1.101 | Reg: 0.00000 | Acc: 67.573% (33786/50000 391/391 \n",
      " [=====================================================================================>]  Step: 46ms | Tot: 3s509ms | Loss: 0.694 | Acc: 78.730% (7873/10000 100/100 p: 32ms | Tot: 227ms | Loss: 0.664 | Acc: 80.375% (643/800 8/100 ...............................]  Step: 36ms | Tot: 295ms | Loss: 0.663 | Acc: 80.300% (803/1000 10/10 11/100 ....................................]  Step: 37ms | Tot: 626ms | Loss: 0.683 | Acc: 79.150% (1583/2000 20/100 33/10 73/100 ..............]  Step: 41ms | Tot: 2s643ms | Loss: 0.700 | Acc: 78.455% (6041/7700 77/100 \n",
      "\n",
      "Epoch: 56\n",
      " [=====================================================================================>]  Step: 151ms | Tot: 58s108ms | Loss: 1.099 | Reg: 0.00000 | Acc: 68.193% (34096/50000 391/391 \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s631ms | Loss: 0.669 | Acc: 80.290% (8029/10000 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 57\n",
      " [=====================================================================================>]  Step: 150ms | Tot: 58s966ms | Loss: 1.076 | Reg: 0.00000 | Acc: 69.100% (34550/50000 391/391 \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s588ms | Loss: 0.755 | Acc: 77.340% (7734/10000 100/100  \n",
      "\n",
      "Epoch: 58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [=====================================================================================>]  Step: 146ms | Tot: 58s843ms | Loss: 1.087 | Reg: 0.00000 | Acc: 68.283% (34141/50000 391/391 \n",
      " [=====================================================================================>]  Step: 37ms | Tot: 3s661ms | Loss: 0.658 | Acc: 79.990% (7999/10000 100/100 \n",
      "\n",
      "Epoch: 59\n",
      " [=====================================================================================>]  Step: 152ms | Tot: 58s793ms | Loss: 1.083 | Reg: 0.00000 | Acc: 68.716% (34357/50000 391/391 \n",
      " [=====================================================================================>]  Step: 38ms | Tot: 3s593ms | Loss: 0.738 | Acc: 76.710% (7671/10000 100/100 ................................]  Step: 38ms | Tot: 439ms | Loss: 0.713 | Acc: 78.429% (1098/1400 14/100 75/100 \n",
      "\n",
      "Epoch: 60\n",
      " [=====================================================================================>]  Step: 160ms | Tot: 1m636ms | Loss: 1.099 | Reg: 0.00000 | Acc: 67.922% (33961/50000 391/391  \n",
      " [=====================================================================================>]  Step: 35ms | Tot: 3s667ms | Loss: 0.666 | Acc: 79.660% (7966/10000 100/100 ................................................]  Step: 35ms | Tot: 320ms | Loss: 0.623 | Acc: 81.300% (813/1000 10/100  33/100 =====>.....................................................]  Step: 45ms | Tot: 1s376ms | Loss: 0.660 | Acc: 80.103% (3124/3900 39/100 ===================>....................................................]  Step: 39ms | Tot: 1s415ms | Loss: 0.660 | Acc: 80.100% (3204/4000 40/100 >.................................................]  Step: 40ms | Tot: 1s575ms | Loss: 0.659 | Acc: 80.205% (3529/4400 44/100 45/100 62/100 91/100 =========>.]  Step: 44ms | Tot: 3s631ms | Loss: 0.667 | Acc: 79.646% (7885/9900 99/100 \n",
      "\n",
      "Epoch: 61\n",
      " [=====================================================================================>]  Step: 152ms | Tot: 1m706ms | Loss: 1.115 | Reg: 0.00000 | Acc: 67.269% (33634/50000 391/391  \n",
      " [=====================================================================================>]  Step: 42ms | Tot: 3s627ms | Loss: 0.718 | Acc: 78.280% (7828/10000 100/100 ==>.........................................................]  Step: 24ms | Tot: 1s173ms | Loss: 0.717 | Acc: 78.412% (2666/3400 34/100 63/100 64/100 66/100 68/100 ===>............]  Step: 44ms | Tot: 3s108ms | Loss: 0.723 | Acc: 78.057% (6791/8700 87/100 ==========================================================================>...........]  Step: 37ms | Tot: 3s145ms | Loss: 0.723 | Acc: 78.034% (6867/8800 88/10 91/100 ==================>......]  Step: 44ms | Tot: 3s346ms | Loss: 0.720 | Acc: 78.151% (7268/9300 93/100 ==================================>.....]  Step: 41ms | Tot: 3s428ms | Loss: 0.721 | Acc: 78.147% (7424/9500 95/100 98/100 99/100 \n",
      "\n",
      "Epoch: 62\n",
      " [=====================================================================================>]  Step: 144ms | Tot: 1m795ms | Loss: 1.100 | Reg: 0.00000 | Acc: 68.313% (34156/50000 391/391  \n",
      " [=====================================================================================>]  Step: 41ms | Tot: 3s674ms | Loss: 0.666 | Acc: 79.850% (7985/10000 100/100 0 .............]  Step: 36ms | Tot: 746ms | Loss: 0.666 | Acc: 79.955% (1759/2200 22/100 25/100 .]  Step: 40ms | Tot: 1s83ms | Loss: 0.671 | Acc: 79.806% (2474/3100 31/10 41/100 59/10 87/100 >.......]  Step: 46ms | Tot: 3s368ms | Loss: 0.668 | Acc: 79.793% (7341/9200 92/100 94/10 99/100 \n",
      "\n",
      "Epoch: 63\n",
      " [=====================================================================================>]  Step: 167ms | Tot: 1m644ms | Loss: 1.083 | Reg: 0.00000 | Acc: 68.563% (34281/50000 391/391  \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s586ms | Loss: 0.737 | Acc: 78.420% (7842/10000 100/100 0 25/100 ............]  Step: 31ms | Tot: 1s13ms | Loss: 0.738 | Acc: 78.774% (2442/3100 31/100 40/100 ..]  Step: 45ms | Tot: 2s449ms | Loss: 0.745 | Acc: 78.157% (5471/7000 70/100 .........]  Step: 32ms | Tot: 2s482ms | Loss: 0.746 | Acc: 78.127% (5547/7100 71/10 74/100 =======>......................]  Step: 46ms | Tot: 2s645ms | Loss: 0.745 | Acc: 78.067% (5855/7500 75/100 91/100 ...]  Step: 38ms | Tot: 3s277ms | Loss: 0.740 | Acc: 78.250% (7199/9200 92/100 =====>....]  Step: 45ms | Tot: 3s442ms | Loss: 0.741 | Acc: 78.229% (7510/9600 96/100 \n",
      "\n",
      "Epoch: 64\n",
      " [=====================================================================================>]  Step: 158ms | Tot: 1m886ms | Loss: 1.077 | Reg: 0.00000 | Acc: 68.992% (34495/50000 391/391  \n",
      " [=====================================================================================>]  Step: 41ms | Tot: 3s668ms | Loss: 0.624 | Acc: 81.390% (8139/10000 100/100 /100 .......]  Step: 45ms | Tot: 2s578ms | Loss: 0.629 | Acc: 81.113% (5759/7100 71/100 >........]  Step: 42ms | Tot: 3s308ms | Loss: 0.624 | Acc: 81.407% (7408/9100 91/100 ..]  Step: 41ms | Tot: 3s468ms | Loss: 0.624 | Acc: 81.421% (7735/9500 95/100 ==================================================================================>..]  Step: 44ms | Tot: 3s591ms | Loss: 0.624 | Acc: 81.408% (7978/9800 98/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 65\n",
      " [=====================================================================================>]  Step: 166ms | Tot: 1m779ms | Loss: 1.076 | Reg: 0.00000 | Acc: 69.241% (34620/50000 391/391  \n",
      " [=====================================================================================>]  Step: 43ms | Tot: 3s616ms | Loss: 0.666 | Acc: 79.760% (7976/10000 100/100 .....................................]  Step: 30ms | Tot: 554ms | Loss: 0.653 | Acc: 81.176% (1380/1700 17/100 ............................]  Step: 40ms | Tot: 690ms | Loss: 0.655 | Acc: 80.857% (1698/2100 21/100 ======================>...............................]  Step: 30ms | Tot: 2s260ms | Loss: 0.672 | Acc: 79.672% (5099/6400 64/100 66/100 90/100 ====>........]  Step: 40ms | Tot: 3s264ms | Loss: 0.670 | Acc: 79.626% (7246/9100 91/100 ===============================>.......]  Step: 40ms | Tot: 3s304ms | Loss: 0.669 | Acc: 79.663% (7329/9200 92/100 =================================>....]  Step: 40ms | Tot: 3s464ms | Loss: 0.670 | Acc: 79.688% (7650/9600 96/100 \n",
      "\n",
      "Epoch: 66\n",
      " [=====================================================================================>]  Step: 151ms | Tot: 1m581ms | Loss: 1.068 | Reg: 0.00000 | Acc: 69.040% (34519/50000 391/391  \n",
      " [=====================================================================================>]  Step: 44ms | Tot: 3s657ms | Loss: 0.640 | Acc: 80.980% (8098/10000 100/100 .......................................]  Step: 38ms | Tot: 771ms | Loss: 0.650 | Acc: 80.318% (1767/2200 22/100 ...........]  Step: 41ms | Tot: 813ms | Loss: 0.646 | Acc: 80.348% (1848/2300 23/100 .....................................]  Step: 42ms | Tot: 1s119ms | Loss: 0.650 | Acc: 80.355% (2491/3100 31/100 ...........]  Step: 42ms | Tot: 1s432ms | Loss: 0.649 | Acc: 80.872% (3154/3900 39/100 .................]  Step: 34ms | Tot: 2s914ms | Loss: 0.648 | Acc: 80.679% (6535/8100 81/100 91/100 \n",
      "\n",
      "Epoch: 67\n",
      " [=====================================================================================>]  Step: 161ms | Tot: 1m447ms | Loss: 1.056 | Reg: 0.00000 | Acc: 69.558% (34778/50000 391/391  \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s697ms | Loss: 0.643 | Acc: 81.520% (8152/10000 100/100 ................]  Step: 44ms | Tot: 548ms | Loss: 0.642 | Acc: 81.438% (1303/1600 16/100 .........]  Step: 39ms | Tot: 930ms | Loss: 0.652 | Acc: 80.889% (2184/2700 27/100 ...........]  Step: 42ms | Tot: 2s182ms | Loss: 0.647 | Acc: 81.417% (4885/6000 60/100 =================================================================>....................]  Step: 29ms | Tot: 2s805ms | Loss: 0.646 | Acc: 81.455% (6272/7700 77/100 ..]  Step: 40ms | Tot: 3s226ms | Loss: 0.647 | Acc: 81.375% (7161/8800 88/10 91/100 92/10 96/100  97/100 ..]  Step: 46ms | Tot: 3s626ms | Loss: 0.644 | Acc: 81.469% (7984/9800 98/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [=====================================================================================>]  Step: 142ms | Tot: 1m703ms | Loss: 1.064 | Reg: 0.00000 | Acc: 69.159% (34579/50000 391/391  \n",
      " [=====================================================================================>]  Step: 32ms | Tot: 3s601ms | Loss: 0.663 | Acc: 80.090% (8009/10000 100/100 ..]  Step: 38ms | Tot: 679ms | Loss: 0.675 | Acc: 79.700% (1594/2000 20/100 33/100 34/100 ...................................................]  Step: 47ms | Tot: 1s408ms | Loss: 0.666 | Acc: 79.923% (3117/3900 39/10 40/100 ==========================>.............................................]  Step: 32ms | Tot: 1s717ms | Loss: 0.664 | Acc: 80.062% (3843/4800 48/10 50/100 =============================================>........................................]  Step: 35ms | Tot: 1s915ms | Loss: 0.661 | Acc: 80.111% (4326/5400 54/100 ..............................]  Step: 30ms | Tot: 1s946ms | Loss: 0.660 | Acc: 80.145% (4408/5500 55/100 ...................................]  Step: 38ms | Tot: 1s984ms | Loss: 0.661 | Acc: 80.196% (4491/5600 56/100 ======================================================>........................]  Step: 26ms | Tot: 2s598ms | Loss: 0.667 | Acc: 79.781% (5824/7300 73/100 ==============================================================>.....................]  Step: 31ms | Tot: 2s699ms | Loss: 0.666 | Acc: 79.842% (6068/7600 76/100 91/100 =========>.......]  Step: 41ms | Tot: 3s295ms | Loss: 0.664 | Acc: 80.043% (7364/9200 92/100 94/100 \n",
      "\n",
      "Epoch: 69\n",
      " [=====================================================================================>]  Step: 156ms | Tot: 59s114ms | Loss: 1.098 | Reg: 0.00000 | Acc: 67.739% (33869/50000 391/391 \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s580ms | Loss: 0.683 | Acc: 80.210% (8021/10000 100/100 ==============================================>............................]  Step: 27ms | Tot: 2s402ms | Loss: 0.676 | Acc: 80.794% (5494/6800 68/10 69/100 \n",
      "\n",
      "Epoch: 70\n",
      " [=====================================================================================>]  Step: 148ms | Tot: 58s815ms | Loss: 1.046 | Reg: 0.00000 | Acc: 69.787% (34893/50000 391/391 \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s671ms | Loss: 0.741 | Acc: 77.280% (7728/10000 100/100 \n",
      "\n",
      "Epoch: 71\n",
      " [=====================================================================================>]  Step: 149ms | Tot: 58s800ms | Loss: 1.083 | Reg: 0.00000 | Acc: 68.327% (34163/50000 391/391 \n",
      " [=====================================================================================>]  Step: 33ms | Tot: 3s641ms | Loss: 0.660 | Acc: 80.660% (8066/10000 100/100 \n",
      "\n",
      "Epoch: 72\n",
      " [=====================================================================================>]  Step: 144ms | Tot: 58s863ms | Loss: 1.046 | Reg: 0.00000 | Acc: 69.702% (34851/50000 391/391 \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s611ms | Loss: 0.681 | Acc: 79.440% (7944/10000 100/100 \n",
      "\n",
      "Epoch: 73\n",
      " [=====================================================================================>]  Step: 152ms | Tot: 58s909ms | Loss: 1.060 | Reg: 0.00000 | Acc: 69.306% (34652/50000 391/391 \n",
      " [=====================================================================================>]  Step: 41ms | Tot: 3s601ms | Loss: 0.662 | Acc: 79.740% (7974/10000 100/100 /100 \n",
      "\n",
      "Epoch: 74\n",
      " [=====================================================================================>]  Step: 151ms | Tot: 58s845ms | Loss: 1.067 | Reg: 0.00000 | Acc: 68.921% (34460/50000 391/391 \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s640ms | Loss: 0.646 | Acc: 81.370% (8137/10000 100/100 \n",
      "\n",
      "Epoch: 75\n",
      " [=====================================================================================>]  Step: 148ms | Tot: 59s35ms | Loss: 1.019 | Reg: 0.00000 | Acc: 71.303% (35651/50000 391/391  \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s663ms | Loss: 0.609 | Acc: 82.620% (8262/10000 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 76\n",
      " [=====================================================================================>]  Step: 155ms | Tot: 59s450ms | Loss: 1.060 | Reg: 0.00000 | Acc: 69.607% (34803/50000 391/391 \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s681ms | Loss: 0.743 | Acc: 77.540% (7754/10000 100/100 tep: 45ms | Tot: 296ms | Loss: 0.741 | Acc: 78.444% (706/900 9/100 ============>.........................................................................]  Step: 37ms | Tot: 494ms | Loss: 0.727 | Acc: 77.733% (1166/1500 15/100 \n",
      "\n",
      "Epoch: 77\n",
      " [=====================================================================================>]  Step: 146ms | Tot: 59s350ms | Loss: 1.078 | Reg: 0.00000 | Acc: 68.614% (34306/50000 391/391 \n",
      " [=====================================================================================>]  Step: 39ms | Tot: 3s678ms | Loss: 0.644 | Acc: 80.900% (8090/10000 100/100 \n",
      "\n",
      "Epoch: 78\n",
      " [=====================================================================================>]  Step: 157ms | Tot: 59s266ms | Loss: 1.047 | Reg: 0.00000 | Acc: 69.903% (34951/50000 391/391 \n",
      " [=====================================================================================>]  Step: 39ms | Tot: 3s600ms | Loss: 0.672 | Acc: 80.690% (8069/10000 100/100 \n",
      "\n",
      "Epoch: 79\n",
      " [=====================================================================================>]  Step: 153ms | Tot: 59s268ms | Loss: 1.043 | Reg: 0.00000 | Acc: 69.716% (34857/50000 391/391 \n",
      " [=====================================================================================>]  Step: 37ms | Tot: 3s819ms | Loss: 0.682 | Acc: 78.740% (7874/10000 100/100 \n",
      "\n",
      "Epoch: 80\n",
      " [=====================================================================================>]  Step: 154ms | Tot: 59s352ms | Loss: 1.093 | Reg: 0.00000 | Acc: 67.912% (33956/50000 391/391 \n",
      " [=====================================================================================>]  Step: 37ms | Tot: 3s667ms | Loss: 0.700 | Acc: 78.490% (7849/10000 100/100 /100 \n",
      "\n",
      "Epoch: 81\n",
      " [=====================================================================================>]  Step: 152ms | Tot: 59s160ms | Loss: 1.049 | Reg: 0.00000 | Acc: 69.561% (34780/50000 391/391 \n",
      " [=====================================================================================>]  Step: 34ms | Tot: 3s675ms | Loss: 0.789 | Acc: 76.380% (7638/10000 100/100 \n",
      "\n",
      "Epoch: 82\n",
      " [=====================================================================================>]  Step: 146ms | Tot: 59s329ms | Loss: 1.054 | Reg: 0.00000 | Acc: 69.351% (34675/50000 391/391 \n",
      " [=====================================================================================>]  Step: 38ms | Tot: 3s650ms | Loss: 0.720 | Acc: 79.510% (7951/10000 100/100 \n",
      "\n",
      "Epoch: 83\n",
      " [=====================================================================================>]  Step: 154ms | Tot: 59s204ms | Loss: 1.052 | Reg: 0.00000 | Acc: 69.503% (34751/50000 391/391 \n",
      " [=====================================================================================>]  Step: 39ms | Tot: 3s605ms | Loss: 0.683 | Acc: 80.470% (8047/10000 100/100 =====>.........................................................................]  Step: 38ms | Tot: 512ms | Loss: 0.666 | Acc: 81.312% (1301/1600 16/100 \n",
      "\n",
      "Epoch: 84\n",
      " [=====================================================================================>]  Step: 152ms | Tot: 59s343ms | Loss: 1.009 | Reg: 0.00000 | Acc: 70.759% (35379/50000 391/391 \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s640ms | Loss: 0.701 | Acc: 78.650% (7865/10000 100/100 \n",
      "\n",
      "Epoch: 85\n",
      " [=====================================================================================>]  Step: 150ms | Tot: 58s698ms | Loss: 1.076 | Reg: 0.00000 | Acc: 68.484% (34242/50000 391/391 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [=====================================================================================>]  Step: 36ms | Tot: 3s616ms | Loss: 0.649 | Acc: 80.810% (8081/10000 100/100 \n",
      "\n",
      "Epoch: 86\n",
      " [=====================================================================================>]  Step: 149ms | Tot: 58s750ms | Loss: 1.043 | Reg: 0.00000 | Acc: 69.932% (34965/50000 391/391 \n",
      " [=====================================================================================>]  Step: 37ms | Tot: 3s789ms | Loss: 0.673 | Acc: 79.550% (7955/10000 100/100 ...................................]  Step: 38ms | Tot: 2s216ms | Loss: 0.673 | Acc: 79.982% (4559/5700 57/100 \n",
      "\n",
      "Epoch: 87\n",
      " [=====================================================================================>]  Step: 153ms | Tot: 58s620ms | Loss: 1.004 | Reg: 0.00000 | Acc: 71.391% (35695/50000 391/391 \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s606ms | Loss: 0.679 | Acc: 79.850% (7985/10000 100/100 \n",
      "\n",
      "Epoch: 88\n",
      " [=====================================================================================>]  Step: 150ms | Tot: 58s978ms | Loss: 1.017 | Reg: 0.00000 | Acc: 70.538% (35269/50000 391/391 \n",
      " [=====================================================================================>]  Step: 37ms | Tot: 3s611ms | Loss: 0.714 | Acc: 77.880% (7788/10000 100/100 \n",
      "\n",
      "Epoch: 89\n",
      " [=====================================================================================>]  Step: 149ms | Tot: 58s917ms | Loss: 1.004 | Reg: 0.00000 | Acc: 71.370% (35684/50000 391/391 \n",
      " [=====================================================================================>]  Step: 40ms | Tot: 3s603ms | Loss: 0.736 | Acc: 77.990% (7799/10000 100/100 \n",
      "\n",
      "Epoch: 90\n",
      " [=====================================================================================>]  Step: 149ms | Tot: 58s833ms | Loss: 1.020 | Reg: 0.00000 | Acc: 70.439% (35219/50000 391/391 \n",
      " [=====================================================================================>]  Step: 33ms | Tot: 3s653ms | Loss: 0.802 | Acc: 76.600% (7660/10000 100/100 \n",
      "\n",
      "Epoch: 91\n",
      " [=====================================================================================>]  Step: 150ms | Tot: 58s761ms | Loss: 1.033 | Reg: 0.00000 | Acc: 69.859% (34929/50000 391/391 \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s593ms | Loss: 0.632 | Acc: 80.900% (8090/10000 100/100 \n",
      "\n",
      "Epoch: 92\n",
      " [=====================================================================================>]  Step: 142ms | Tot: 58s927ms | Loss: 0.991 | Reg: 0.00000 | Acc: 71.267% (35633/50000 391/391 \n",
      " [=====================================================================================>]  Step: 35ms | Tot: 3s638ms | Loss: 0.630 | Acc: 81.660% (8166/10000 100/100 \n",
      "\n",
      "Epoch: 93\n",
      " [=====================================================================================>]  Step: 148ms | Tot: 58s980ms | Loss: 1.020 | Reg: 0.00000 | Acc: 70.241% (35120/50000 391/391 \n",
      " [=====================================================================================>]  Step: 32ms | Tot: 3s608ms | Loss: 0.592 | Acc: 81.750% (8175/10000 100/100 ..]  Step: 25ms | Tot: 521ms | Loss: 0.575 | Acc: 82.250% (1316/1600 16/100 \n",
      "\n",
      "Epoch: 94\n",
      " [=====================================================================================>]  Step: 147ms | Tot: 58s871ms | Loss: 1.000 | Reg: 0.00000 | Acc: 71.314% (35657/50000 391/391 \n",
      " [=====================================================================================>]  Step: 41ms | Tot: 3s650ms | Loss: 0.761 | Acc: 77.980% (7798/10000 100/100 \n",
      "\n",
      "Epoch: 95\n",
      " [=====================================================================================>]  Step: 151ms | Tot: 58s765ms | Loss: 1.005 | Reg: 0.00000 | Acc: 70.973% (35486/50000 391/391 \n",
      " [=====================================================================================>]  Step: 38ms | Tot: 3s635ms | Loss: 0.618 | Acc: 82.700% (8270/10000 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 96\n",
      " [=====================================================================================>]  Step: 145ms | Tot: 58s769ms | Loss: 1.046 | Reg: 0.00000 | Acc: 69.494% (34747/50000 391/391 \n",
      " [=====================================================================================>]  Step: 35ms | Tot: 3s634ms | Loss: 0.742 | Acc: 77.930% (7793/10000 100/100 \n",
      "\n",
      "Epoch: 97\n",
      " [=====================================================================================>]  Step: 150ms | Tot: 59s1ms | Loss: 1.015 | Reg: 0.00000 | Acc: 70.844% (35421/50000 391/391 1 \n",
      " [=====================================================================================>]  Step: 35ms | Tot: 3s648ms | Loss: 0.673 | Acc: 78.840% (7884/10000 100/100 \n",
      "\n",
      "Epoch: 98\n",
      " [=====================================================================================>]  Step: 147ms | Tot: 59s348ms | Loss: 0.993 | Reg: 0.00000 | Acc: 71.417% (35708/50000 391/391 \n",
      " [=====================================================================================>]  Step: 37ms | Tot: 3s618ms | Loss: 0.657 | Acc: 81.370% (8137/10000 100/100 ......................................................]  Step: 28ms | Tot: 635ms | Loss: 0.643 | Acc: 81.474% (1548/1900 19/100 \n",
      "\n",
      "Epoch: 99\n",
      " [=====================================================================================>]  Step: 150ms | Tot: 59s455ms | Loss: 1.033 | Reg: 0.00000 | Acc: 70.182% (35091/50000 391/391 \n",
      " [=====================================================================================>]  Step: 38ms | Tot: 3s645ms | Loss: 0.681 | Acc: 80.070% (8007/10000 100/100 \n",
      "\n",
      "Epoch: 100\n",
      " [=====================================================================================>]  Step: 158ms | Tot: 59s371ms | Loss: 1.061 | Reg: 0.00000 | Acc: 68.960% (34480/50000 391/391 \n",
      " [=====================================================================================>]  Step: 37ms | Tot: 3s686ms | Loss: 0.622 | Acc: 82.070% (8207/10000 100/100 \n",
      "\n",
      "Epoch: 101\n",
      " [=====================================================================================>]  Step: 150ms | Tot: 59s621ms | Loss: 1.007 | Reg: 0.00000 | Acc: 70.574% (35287/50000 391/391 \n",
      " [=====================================================================================>]  Step: 35ms | Tot: 3s661ms | Loss: 0.601 | Acc: 82.700% (8270/10000 100/100 \n",
      "\n",
      "Epoch: 102\n",
      " [=====================================================================================>]  Step: 147ms | Tot: 59s418ms | Loss: 0.950 | Reg: 0.00000 | Acc: 72.698% (36348/50000 391/391 \n",
      " [=====================================================================================>]  Step: 37ms | Tot: 3s633ms | Loss: 0.600 | Acc: 82.770% (8277/10000 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 103\n",
      " [=====================================================================================>]  Step: 146ms | Tot: 59s132ms | Loss: 0.961 | Reg: 0.00000 | Acc: 72.675% (36337/50000 391/391 \n",
      " [=====================================================================================>]  Step: 37ms | Tot: 3s693ms | Loss: 0.619 | Acc: 82.720% (8272/10000 100/100 /100 \n",
      "\n",
      "Epoch: 104\n",
      " [=====================================================================================>]  Step: 150ms | Tot: 59s503ms | Loss: 0.992 | Reg: 0.00000 | Acc: 71.495% (35747/50000 391/391 \n",
      " [=====================================================================================>]  Step: 37ms | Tot: 3s614ms | Loss: 0.612 | Acc: 82.710% (8271/10000 100/100 \n",
      "\n",
      "Epoch: 105\n",
      " [=====================================================================================>]  Step: 148ms | Tot: 59s373ms | Loss: 0.942 | Reg: 0.00000 | Acc: 73.362% (36680/50000 391/391 \n",
      " [=====================================================================================>]  Step: 41ms | Tot: 3s696ms | Loss: 0.607 | Acc: 82.080% (8208/10000 100/100 \n",
      "\n",
      "Epoch: 106\n",
      " [=====================================================================================>]  Step: 148ms | Tot: 59s285ms | Loss: 0.978 | Reg: 0.00000 | Acc: 71.503% (35751/50000 391/391 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [=====================================================================================>]  Step: 35ms | Tot: 3s528ms | Loss: 0.613 | Acc: 82.520% (8252/10000 100/100 ==========>..........................................................................]  Step: 37ms | Tot: 438ms | Loss: 0.609 | Acc: 82.857% (1160/1400 14/100 \n",
      "\n",
      "Epoch: 107\n",
      " [=====================================================================================>]  Step: 152ms | Tot: 58s836ms | Loss: 0.977 | Reg: 0.00000 | Acc: 71.789% (35894/50000 391/391 \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s893ms | Loss: 0.606 | Acc: 81.860% (8186/10000 100/100   Step: 41ms | Tot: 1s605ms | Loss: 0.614 | Acc: 81.477% (3585/4400 44/100 ........]  Step: 40ms | Tot: 1s682ms | Loss: 0.608 | Acc: 81.652% (3756/4600 46/100 \n",
      "\n",
      "Epoch: 108\n",
      " [=====================================================================================>]  Step: 146ms | Tot: 58s525ms | Loss: 0.940 | Reg: 0.00000 | Acc: 73.424% (36712/50000 391/391 \n",
      " [=====================================================================================>]  Step: 35ms | Tot: 3s575ms | Loss: 0.593 | Acc: 83.120% (8312/10000 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 109\n",
      " [=====================================================================================>]  Step: 147ms | Tot: 59s64ms | Loss: 0.948 | Reg: 0.00000 | Acc: 72.986% (36493/50000 391/391  \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s611ms | Loss: 0.594 | Acc: 82.590% (8259/10000 100/100 \n",
      "\n",
      "Epoch: 110\n",
      " [=====================================================================================>]  Step: 149ms | Tot: 58s415ms | Loss: 0.960 | Reg: 0.00000 | Acc: 72.765% (36382/50000 391/391 \n",
      " [=====================================================================================>]  Step: 38ms | Tot: 3s611ms | Loss: 0.598 | Acc: 83.330% (8333/10000 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 111\n",
      " [=====================================================================================>]  Step: 152ms | Tot: 59s141ms | Loss: 0.973 | Reg: 0.00000 | Acc: 71.892% (35945/50000 391/391 \n",
      " [=====================================================================================>]  Step: 32ms | Tot: 3s664ms | Loss: 0.616 | Acc: 82.770% (8277/10000 100/100  Step: 37ms | Tot: 1s268ms | Loss: 0.622 | Acc: 82.417% (2967/3600 36/100 \n",
      "\n",
      "Epoch: 112\n",
      " [=====================================================================================>]  Step: 153ms | Tot: 1m606ms | Loss: 0.939 | Reg: 0.00000 | Acc: 72.878% (36438/50000 391/391  \n",
      " [====================================================================================>.]  Step: 40ms | Tot: 3s619ms | Loss: 0.604 | Acc: 83.172% (8234/9900 99/100 ]  Step: 25ms | Tot: 342ms | Loss: 0.611 | Acc: 82.636% (909/1100 11/100 .....................]  Step: 33ms | Tot: 376ms | Loss: 0.606 | Acc: 82.750% (993/1200 12/100 16/10 38/100 ........................................]  Step: 42ms | Tot: 1s380ms | Loss: 0.611 | Acc: 83.103% (3241/3900 39/100 ....]  Step: 38ms | Tot: 1s418ms | Loss: 0.611 | Acc: 83.075% (3323/4000 40/100 ..........................]  Step: 40ms | Tot: 2s404ms | Loss: 0.605 | Acc: 83.000% (5561/6700 67/100 ========>...........]  Step: 44ms | Tot: 3s190ms | Loss: 0.605 | Acc: 83.057% (7309/8800 88/100   Step: 42ms | Tot: 3s270ms | Loss: 0.605 | Acc: 83.044% (7474/9000 90/100 91/100 =========>]  Step: 41ms | Tot: 3s660ms | Loss: 0.603 | Acc: 83.200% (8320/10000 100/100 \n",
      "\n",
      "Epoch: 113\n",
      " [=====================================================================================>]  Step: 163ms | Tot: 1m1s | Loss: 0.906 | Reg: 0.00000 | Acc: 74.854% (37427/50000 391/391 91  \n",
      " [=====================================================================================>]  Step: 40ms | Tot: 3s720ms | Loss: 0.606 | Acc: 82.290% (8229/10000 100/100 ....................................]  Step: 44ms | Tot: 380ms | Loss: 0.613 | Acc: 81.818% (900/1100 11/100 ..............]  Step: 37ms | Tot: 535ms | Loss: 0.599 | Acc: 82.400% (1236/1500 15/100 .]  Step: 40ms | Tot: 651ms | Loss: 0.599 | Acc: 82.667% (1488/1800 18/100 .............................]  Step: 40ms | Tot: 2s381ms | Loss: 0.605 | Acc: 82.200% (5343/6500 65/100 ====================================================================>...........]  Step: 40ms | Tot: 3s242ms | Loss: 0.606 | Acc: 82.170% (7231/8800 88/100 =============>......]  Step: 41ms | Tot: 3s485ms | Loss: 0.608 | Acc: 82.213% (7728/9400 94/100 ====>....]  Step: 41ms | Tot: 3s566ms | Loss: 0.609 | Acc: 82.167% (7888/9600 96/10 99/100 \n",
      "\n",
      "Epoch: 114\n",
      " [=====================================================================================>]  Step: 159ms | Tot: 1m1s | Loss: 0.964 | Reg: 0.00000 | Acc: 72.056% (36027/50000 391/391 91  \n",
      " [=====================================================================================>]  Step: 42ms | Tot: 3s708ms | Loss: 0.601 | Acc: 83.140% (8314/10000 100/100 ........]  Step: 50ms | Tot: 2s375ms | Loss: 0.602 | Acc: 83.031% (5397/6500 65/100 ]  Step: 45ms | Tot: 2s486ms | Loss: 0.603 | Acc: 82.956% (5641/6800 68/100 ]  Step: 44ms | Tot: 2s604ms | Loss: 0.609 | Acc: 82.789% (5878/7100 71/10 89/100 ========>.........]  Step: 44ms | Tot: 3s322ms | Loss: 0.603 | Acc: 82.967% (7467/9000 90/100 \n",
      "\n",
      "Epoch: 115\n",
      " [=====================================================================================>]  Step: 162ms | Tot: 1m1s | Loss: 0.940 | Reg: 0.00000 | Acc: 73.191% (36595/50000 391/391 91  \n",
      " [=====================================================================================>]  Step: 39ms | Tot: 3s686ms | Loss: 0.602 | Acc: 81.860% (8186/10000 100/100 =================================================================>.............]  Step: 34ms | Tot: 3s92ms | Loss: 0.605 | Acc: 81.671% (6942/8500 85/100 ============================================================================>..]  Step: 36ms | Tot: 3s614ms | Loss: 0.603 | Acc: 81.837% (8020/9800 98/100 \n",
      "\n",
      "Epoch: 116\n",
      " [=====================================================================================>]  Step: 164ms | Tot: 1m1s | Loss: 0.959 | Reg: 0.00000 | Acc: 72.435% (36217/50000 391/391 91  \n",
      " [=====================================================================================>]  Step: 38ms | Tot: 3s611ms | Loss: 0.613 | Acc: 83.200% (8320/10000 100/100 40/100 79/100 ===================================>......]  Step: 41ms | Tot: 3s339ms | Loss: 0.615 | Acc: 83.108% (7729/9300 93/100 =========>.]  Step: 38ms | Tot: 3s573ms | Loss: 0.613 | Acc: 83.172% (8234/9900 99/100 \n",
      "\n",
      "Epoch: 117\n",
      " [=====================================================================================>]  Step: 151ms | Tot: 1m1s | Loss: 0.961 | Reg: 0.00000 | Acc: 72.333% (36166/50000 391/391 91  \n",
      " [=====================================================================================>]  Step: 40ms | Tot: 3s634ms | Loss: 0.590 | Acc: 83.600% (8360/10000 100/100 ep: 29ms | Tot: 1s14ms | Loss: 0.589 | Acc: 83.621% (2425/2900 29/100 ======================================>.............................................]  Step: 35ms | Tot: 1s710ms | Loss: 0.592 | Acc: 83.625% (4014/4800 48/100 =========>......]  Step: 43ms | Tot: 3s372ms | Loss: 0.592 | Acc: 83.527% (7768/9300 93/10 95/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 118\n",
      " [=====================================================================================>]  Step: 168ms | Tot: 1m887ms | Loss: 0.889 | Reg: 0.00000 | Acc: 75.218% (37609/50000 391/391  \n",
      " [=====================================================================================>]  Step: 40ms | Tot: 3s613ms | Loss: 0.605 | Acc: 82.270% (8227/10000 100/100 ...................................]  Step: 31ms | Tot: 376ms | Loss: 0.605 | Acc: 81.818% (900/1100 11/10 58/100 .]  Step: 35ms | Tot: 2s151ms | Loss: 0.605 | Acc: 82.000% (5084/6200 62/100   Step: 42ms | Tot: 3s573ms | Loss: 0.606 | Acc: 82.253% (8143/9900 99/100 \n",
      "\n",
      "Epoch: 119\n",
      " [=====================================================================================>]  Step: 158ms | Tot: 1m1s | Loss: 0.950 | Reg: 0.00000 | Acc: 73.000% (36500/50000 391/391 91  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [=====================================================================================>]  Step: 38ms | Tot: 3s658ms | Loss: 0.635 | Acc: 81.690% (8169/10000)9/100 1/10 94/100 100/100 \n",
      "\n",
      "Epoch: 120\n",
      " [=====================================================================================>]  Step: 151ms | Tot: 1m1s | Loss: 0.963 | Reg: 0.00000 | Acc: 71.972% (35986/50000 391/391 91  \n",
      " [=====================================================================================>]  Step: 39ms | Tot: 3s700ms | Loss: 0.600 | Acc: 82.910% (8291/10000 100/100 tep: 42ms | Tot: 415ms | Loss: 0.595 | Acc: 82.500% (990/1200 12/100 .........]  Step: 43ms | Tot: 3s149ms | Loss: 0.603 | Acc: 82.756% (7117/8600 86/100 ========>..]  Step: 38ms | Tot: 3s631ms | Loss: 0.601 | Acc: 82.888% (8123/9800 98/100 \n",
      "\n",
      "Epoch: 121\n",
      " [=====================================================================================>]  Step: 147ms | Tot: 59s547ms | Loss: 0.944 | Reg: 0.00000 | Acc: 72.869% (36434/50000 391/391 \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s569ms | Loss: 0.602 | Acc: 83.430% (8343/10000 100/100 \n",
      "\n",
      "Epoch: 122\n",
      " [=====================================================================================>]  Step: 151ms | Tot: 59s271ms | Loss: 0.983 | Reg: 0.00000 | Acc: 71.333% (35666/50000 391/391 \n",
      " [=====================================================================================>]  Step: 38ms | Tot: 3s679ms | Loss: 0.591 | Acc: 82.700% (8270/10000 100/100 \n",
      "\n",
      "Epoch: 123\n",
      " [=====================================================================================>]  Step: 156ms | Tot: 58s823ms | Loss: 1.009 | Reg: 0.00000 | Acc: 70.081% (35040/50000 391/391 \n",
      " [=====================================================================================>]  Step: 38ms | Tot: 3s646ms | Loss: 0.581 | Acc: 83.780% (8378/10000 100/100 /100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 124\n",
      " [=====================================================================================>]  Step: 149ms | Tot: 59s328ms | Loss: 0.929 | Reg: 0.00000 | Acc: 72.914% (36456/50000 391/391 \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s647ms | Loss: 0.579 | Acc: 82.910% (8291/10000 100/100 \n",
      "\n",
      "Epoch: 125\n",
      " [=====================================================================================>]  Step: 146ms | Tot: 59s182ms | Loss: 0.953 | Reg: 0.00000 | Acc: 72.051% (36025/50000 391/391 \n",
      " [=====================================================================================>]  Step: 44ms | Tot: 3s859ms | Loss: 0.574 | Acc: 83.160% (8316/10000 100/100 \n",
      "\n",
      "Epoch: 126\n",
      " [=====================================================================================>]  Step: 152ms | Tot: 58s968ms | Loss: 0.971 | Reg: 0.00000 | Acc: 71.497% (35748/50000 391/391 \n",
      " [=====================================================================================>]  Step: 37ms | Tot: 3s668ms | Loss: 0.574 | Acc: 83.030% (8303/10000 100/100 0 \n",
      "\n",
      "Epoch: 127\n",
      " [=====================================================================================>]  Step: 153ms | Tot: 59s3ms | Loss: 0.979 | Reg: 0.00000 | Acc: 71.480% (35740/50000 391/391 1 \n",
      " [=====================================================================================>]  Step: 37ms | Tot: 3s591ms | Loss: 0.573 | Acc: 83.140% (8314/10000 100/100 \n",
      "\n",
      "Epoch: 128\n",
      " [=====================================================================================>]  Step: 149ms | Tot: 58s991ms | Loss: 0.930 | Reg: 0.00000 | Acc: 73.143% (36571/50000 391/391 \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s639ms | Loss: 0.605 | Acc: 82.530% (8253/10000 100/100 \n",
      "\n",
      "Epoch: 129\n",
      " [=====================================================================================>]  Step: 151ms | Tot: 58s890ms | Loss: 0.947 | Reg: 0.00000 | Acc: 72.682% (36340/50000 391/391 \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s639ms | Loss: 0.577 | Acc: 83.370% (8337/10000 100/100 \n",
      "\n",
      "Epoch: 130\n",
      " [=====================================================================================>]  Step: 151ms | Tot: 58s645ms | Loss: 0.932 | Reg: 0.00000 | Acc: 73.295% (36647/50000 391/391 \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s605ms | Loss: 0.618 | Acc: 82.760% (8276/10000 100/100 \n",
      "\n",
      "Epoch: 131\n",
      " [=====================================================================================>]  Step: 147ms | Tot: 58s880ms | Loss: 0.967 | Reg: 0.00000 | Acc: 71.555% (35777/50000 391/391 \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s831ms | Loss: 0.589 | Acc: 82.950% (8295/10000 100/100 /100 \n",
      "\n",
      "Epoch: 132\n",
      " [=====================================================================================>]  Step: 145ms | Tot: 59s191ms | Loss: 0.924 | Reg: 0.00000 | Acc: 73.378% (36689/50000 391/391 \n",
      " [=====================================================================================>]  Step: 35ms | Tot: 3s622ms | Loss: 0.601 | Acc: 82.830% (8283/10000 100/100 \n",
      "\n",
      "Epoch: 133\n",
      " [=====================================================================================>]  Step: 151ms | Tot: 59s214ms | Loss: 0.935 | Reg: 0.00000 | Acc: 72.948% (36474/50000 391/391 \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s667ms | Loss: 0.599 | Acc: 81.930% (8193/10000 100/100 10 12/100 \n",
      "\n",
      "Epoch: 134\n",
      " [=====================================================================================>]  Step: 151ms | Tot: 59s230ms | Loss: 0.962 | Reg: 0.00000 | Acc: 72.038% (36018/50000 391/391 \n",
      " [=====================================================================================>]  Step: 32ms | Tot: 3s689ms | Loss: 0.577 | Acc: 83.380% (8338/10000 100/100 =============================>..................................................]  Step: 43ms | Tot: 1s515ms | Loss: 0.581 | Acc: 83.429% (3504/4200 42/100 .................]  Step: 42ms | Tot: 1s952ms | Loss: 0.577 | Acc: 83.453% (4423/5300 53/100 ...]  Step: 37ms | Tot: 3s84ms | Loss: 0.579 | Acc: 83.333% (7000/8400 84/100 \n",
      "\n",
      "Epoch: 135\n",
      " [=====================================================================================>]  Step: 150ms | Tot: 59s331ms | Loss: 0.976 | Reg: 0.00000 | Acc: 71.527% (35763/50000 391/391 \n",
      " [=====================================================================================>]  Step: 39ms | Tot: 3s672ms | Loss: 0.613 | Acc: 82.790% (8279/10000 100/100 \n",
      "\n",
      "Epoch: 136\n",
      " [=====================================================================================>]  Step: 156ms | Tot: 59s313ms | Loss: 0.911 | Reg: 0.00000 | Acc: 74.266% (37132/50000 391/391 \n",
      " [=====================================================================================>]  Step: 37ms | Tot: 3s693ms | Loss: 0.609 | Acc: 82.280% (8228/10000 100/100 100 87/100 \n",
      "\n",
      "Epoch: 137\n",
      " [=====================================================================================>]  Step: 154ms | Tot: 59s243ms | Loss: 0.958 | Reg: 0.00000 | Acc: 72.285% (36142/50000 391/391 \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s570ms | Loss: 0.595 | Acc: 83.240% (8324/10000 100/100 ..........................................................................]  Step: 40ms | Tot: 222ms | Loss: 0.593 | Acc: 83.500% (668/800 8/10 71/100 \n",
      "\n",
      "Epoch: 138\n",
      " [=====================================================================================>]  Step: 153ms | Tot: 59s317ms | Loss: 0.936 | Reg: 0.00000 | Acc: 73.063% (36531/50000 391/391 \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s690ms | Loss: 0.586 | Acc: 83.410% (8341/10000 100/100 100 \n",
      "\n",
      "Epoch: 139\n",
      " [=====================================================================================>]  Step: 152ms | Tot: 59s438ms | Loss: 0.949 | Reg: 0.00000 | Acc: 72.455% (36227/50000 391/391 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [=====================================================================================>]  Step: 35ms | Tot: 3s654ms | Loss: 0.596 | Acc: 82.520% (8252/10000 100/100 \n",
      "\n",
      "Epoch: 140\n",
      " [=====================================================================================>]  Step: 155ms | Tot: 1m409ms | Loss: 0.963 | Reg: 0.00000 | Acc: 71.668% (35833/50000 391/391  \n",
      " [=====================================================================================>]  Step: 40ms | Tot: 3s722ms | Loss: 0.587 | Acc: 83.470% (8347/10000 100/100 100 \n",
      "\n",
      "Epoch: 141\n",
      " [=====================================================================================>]  Step: 154ms | Tot: 1m425ms | Loss: 0.972 | Reg: 0.00000 | Acc: 71.292% (35646/50000 391/391  \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s697ms | Loss: 0.580 | Acc: 83.840% (8384/10000 100/100 100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 142\n",
      " [=====================================================================================>]  Step: 159ms | Tot: 1m555ms | Loss: 0.946 | Reg: 0.00000 | Acc: 72.331% (36165/50000 391/391  \n",
      " [=====================================================================================>]  Step: 33ms | Tot: 3s721ms | Loss: 0.624 | Acc: 82.450% (8245/10000 100/100 \n",
      "\n",
      "Epoch: 143\n",
      " [=====================================================================================>]  Step: 155ms | Tot: 1m480ms | Loss: 0.954 | Reg: 0.00000 | Acc: 72.229% (36114/50000 391/391  \n",
      " [=====================================================================================>]  Step: 43ms | Tot: 3s725ms | Loss: 0.584 | Acc: 83.520% (8352/10000 100/100 100 52/100 \n",
      "\n",
      "Epoch: 144\n",
      " [=====================================================================================>]  Step: 150ms | Tot: 1m743ms | Loss: 0.937 | Reg: 0.00000 | Acc: 73.083% (36541/50000 391/391  \n",
      " [=====================================================================================>]  Step: 38ms | Tot: 3s720ms | Loss: 0.596 | Acc: 82.920% (8292/10000 100/100 \n",
      "\n",
      "Epoch: 145\n",
      " [=====================================================================================>]  Step: 162ms | Tot: 1m681ms | Loss: 0.936 | Reg: 0.00000 | Acc: 72.960% (36480/50000 391/391  \n",
      " [=====================================================================================>]  Step: 39ms | Tot: 3s662ms | Loss: 0.608 | Acc: 82.280% (8228/10000 100/100 .]  Step: 34ms | Tot: 268ms | Loss: 0.585 | Acc: 82.800% (828/1000 10/100 =====================================================>...........................]  Step: 40ms | Tot: 2s491ms | Loss: 0.612 | Acc: 82.000% (5658/6900 69/100 ============>..........................]  Step: 38ms | Tot: 2s530ms | Loss: 0.614 | Acc: 81.929% (5735/7000 70/100 \n",
      "\n",
      "Epoch: 146\n",
      " [=====================================================================================>]  Step: 142ms | Tot: 1m729ms | Loss: 0.960 | Reg: 0.00000 | Acc: 71.975% (35987/50000 391/391  \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s730ms | Loss: 0.621 | Acc: 82.660% (8266/10000 100/100 0 66/100 ....]  Step: 42ms | Tot: 3s349ms | Loss: 0.623 | Acc: 82.556% (7430/9000 90/100 \n",
      "\n",
      "Epoch: 147\n",
      " [=====================================================================================>]  Step: 159ms | Tot: 1m798ms | Loss: 0.892 | Reg: 0.00000 | Acc: 74.986% (37492/50000 391/391  \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s719ms | Loss: 0.595 | Acc: 82.890% (8289/10000 100/100 \n",
      "\n",
      "Epoch: 148\n",
      " [=====================================================================================>]  Step: 158ms | Tot: 1m727ms | Loss: 0.917 | Reg: 0.00000 | Acc: 73.898% (36949/50000 391/391  \n",
      " [=====================================================================================>]  Step: 27ms | Tot: 3s956ms | Loss: 0.582 | Acc: 83.410% (8341/10000 100/100 ..........................]  Step: 41ms | Tot: 1s586ms | Loss: 0.580 | Acc: 83.791% (3603/4300 43/100 44/10 56/100 \n",
      "\n",
      "Epoch: 149\n",
      " [=====================================================================================>]  Step: 156ms | Tot: 1m2ms | Loss: 0.908 | Reg: 0.00000 | Acc: 74.117% (37058/50000 391/391 91 \n",
      " [=====================================================================================>]  Step: 41ms | Tot: 3s908ms | Loss: 0.594 | Acc: 82.950% (8295/10000 100/100 \n",
      "\n",
      "Epoch: 150\n",
      " [=====================================================================================>]  Step: 155ms | Tot: 59s694ms | Loss: 0.917 | Reg: 0.00000 | Acc: 73.619% (36809/50000 391/391 \n",
      " [=====================================================================================>]  Step: 37ms | Tot: 3s666ms | Loss: 0.604 | Acc: 82.700% (8270/10000 100/100 \n",
      "\n",
      "Epoch: 151\n",
      " [=====================================================================================>]  Step: 153ms | Tot: 59s389ms | Loss: 0.940 | Reg: 0.00000 | Acc: 72.697% (36348/50000 391/391 \n",
      " [=====================================================================================>]  Step: 37ms | Tot: 3s678ms | Loss: 0.588 | Acc: 83.450% (8345/10000 100/100 \n",
      "\n",
      "Epoch: 152\n",
      " [=====================================================================================>]  Step: 155ms | Tot: 59s432ms | Loss: 0.949 | Reg: 0.00000 | Acc: 71.903% (35951/50000 391/391 \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s674ms | Loss: 0.613 | Acc: 82.540% (8254/10000 100/100 \n",
      "\n",
      "Epoch: 153\n",
      " [=====================================================================================>]  Step: 150ms | Tot: 59s207ms | Loss: 0.946 | Reg: 0.00000 | Acc: 72.835% (36417/50000 391/391 \n",
      " [=====================================================================================>]  Step: 35ms | Tot: 3s650ms | Loss: 0.604 | Acc: 83.240% (8324/10000 100/100 \n",
      "\n",
      "Epoch: 154\n",
      " [=====================================================================================>]  Step: 152ms | Tot: 58s895ms | Loss: 0.947 | Reg: 0.00000 | Acc: 72.015% (36007/50000 391/391 \n",
      " [=====================================================================================>]  Step: 38ms | Tot: 3s616ms | Loss: 0.602 | Acc: 82.530% (8253/10000 100/100 ...............................................................................]  Step: 35ms | Tot: 228ms | Loss: 0.581 | Acc: 84.125% (673/800 8/100 \n",
      "\n",
      "Epoch: 155\n",
      " [=====================================================================================>]  Step: 150ms | Tot: 59s75ms | Loss: 0.921 | Reg: 0.00000 | Acc: 73.176% (36587/50000 391/391  \n",
      " [=====================================================================================>]  Step: 38ms | Tot: 3s879ms | Loss: 0.589 | Acc: 83.420% (8342/10000 100/100 \n",
      "\n",
      "Epoch: 156\n",
      " [=====================================================================================>]  Step: 153ms | Tot: 58s965ms | Loss: 0.922 | Reg: 0.00000 | Acc: 73.333% (36666/50000 391/391 \n",
      " [=====================================================================================>]  Step: 37ms | Tot: 3s649ms | Loss: 0.580 | Acc: 83.530% (8353/10000 100/100   Step: 39ms | Tot: 2s428ms | Loss: 0.581 | Acc: 83.433% (5590/6700 67/100 \n",
      "\n",
      "Epoch: 157\n",
      " [=====================================================================================>]  Step: 151ms | Tot: 58s934ms | Loss: 0.885 | Reg: 0.00000 | Acc: 74.802% (37400/50000 391/391 \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s632ms | Loss: 0.566 | Acc: 84.320% (8432/10000 100/100 \n",
      "Saving..\n",
      "\n",
      "Epoch: 158\n",
      " [=====================================================================================>]  Step: 146ms | Tot: 58s792ms | Loss: 0.963 | Reg: 0.00000 | Acc: 71.899% (35949/50000 391/391 \n",
      " [=====================================================================================>]  Step: 37ms | Tot: 3s607ms | Loss: 0.590 | Acc: 83.270% (8327/10000 100/100 \n",
      "\n",
      "Epoch: 159\n",
      " [=====================================================================================>]  Step: 145ms | Tot: 58s360ms | Loss: 0.958 | Reg: 0.00000 | Acc: 71.760% (35880/50000 391/391 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [=====================================================================================>]  Step: 37ms | Tot: 3s546ms | Loss: 0.584 | Acc: 83.690% (8369/10000 100/100 0/100 \n",
      "\n",
      "Epoch: 160\n",
      " [=====================================================================================>]  Step: 152ms | Tot: 57s956ms | Loss: 0.896 | Reg: 0.00000 | Acc: 74.356% (37177/50000 391/391 \n",
      " [=====================================================================================>]  Step: 37ms | Tot: 3s537ms | Loss: 0.576 | Acc: 83.890% (8389/10000 100/100 ...............................................................................]  Step: 38ms | Tot: 228ms | Loss: 0.562 | Acc: 85.250% (682/800 8/10 10/100 ]  Step: 41ms | Tot: 488ms | Loss: 0.567 | Acc: 84.938% (1359/1600 16/100 \n",
      "\n",
      "Epoch: 161\n",
      " [=====================================================================================>]  Step: 151ms | Tot: 58s241ms | Loss: 0.917 | Reg: 0.00000 | Acc: 73.533% (36766/50000 391/391 \n",
      " [=====================================================================================>]  Step: 37ms | Tot: 3s573ms | Loss: 0.592 | Acc: 83.230% (8323/10000 100/100 \n",
      "\n",
      "Epoch: 162\n",
      " [=====================================================================================>]  Step: 151ms | Tot: 58s560ms | Loss: 0.928 | Reg: 0.00000 | Acc: 72.970% (36484/50000 391/391 \n",
      " [=====================================================================================>]  Step: 37ms | Tot: 3s589ms | Loss: 0.582 | Acc: 83.290% (8329/10000 100/100 \n",
      "\n",
      "Epoch: 163\n",
      " [=====================================================================================>]  Step: 145ms | Tot: 59s195ms | Loss: 0.918 | Reg: 0.00000 | Acc: 73.671% (36835/50000 391/391 \n",
      " [=====================================================================================>]  Step: 37ms | Tot: 3s917ms | Loss: 0.582 | Acc: 83.820% (8382/10000 100/100 /100 \n",
      "\n",
      "Epoch: 164\n",
      " [=====================================================================================>]  Step: 147ms | Tot: 59s285ms | Loss: 0.948 | Reg: 0.00000 | Acc: 71.821% (35910/50000 391/391 \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s646ms | Loss: 0.589 | Acc: 83.510% (8351/10000 100/100 \n",
      "\n",
      "Epoch: 165\n",
      " [=====================================================================================>]  Step: 158ms | Tot: 59s289ms | Loss: 0.909 | Reg: 0.00000 | Acc: 74.164% (37082/50000 391/391 \n",
      " [=====================================================================================>]  Step: 37ms | Tot: 3s680ms | Loss: 0.594 | Acc: 83.300% (8330/10000 100/100 \n",
      "\n",
      "Epoch: 166\n",
      " [=====================================================================================>]  Step: 150ms | Tot: 59s426ms | Loss: 0.910 | Reg: 0.00000 | Acc: 73.899% (36949/50000 391/391 \n",
      " [=====================================================================================>]  Step: 35ms | Tot: 3s678ms | Loss: 0.583 | Acc: 83.530% (8353/10000 100/100 ....................................................]  Step: 34ms | Tot: 202ms | Loss: 0.546 | Acc: 85.000% (595/700 7/100 \n",
      "\n",
      "Epoch: 167\n",
      " [=====================================================================================>]  Step: 157ms | Tot: 59s469ms | Loss: 0.939 | Reg: 0.00000 | Acc: 72.883% (36441/50000 391/391 \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s638ms | Loss: 0.575 | Acc: 83.790% (8379/10000 100/100 =====================================================================>..............]  Step: 37ms | Tot: 3s46ms | Loss: 0.577 | Acc: 83.679% (7029/8400 84/100 \n",
      "\n",
      "Epoch: 168\n",
      " [=====================================================================================>]  Step: 155ms | Tot: 59s375ms | Loss: 0.949 | Reg: 0.00000 | Acc: 72.678% (36338/50000 391/391 \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s598ms | Loss: 0.583 | Acc: 83.520% (8352/10000 100/100 ..............]  Step: 28ms | Tot: 555ms | Loss: 0.563 | Acc: 84.471% (1436/1700 17/100 \n",
      "\n",
      "Epoch: 169\n",
      " [=====================================================================================>]  Step: 150ms | Tot: 59s574ms | Loss: 0.953 | Reg: 0.00000 | Acc: 72.391% (36195/50000 391/391 \n",
      " [=====================================================================================>]  Step: 37ms | Tot: 3s635ms | Loss: 0.592 | Acc: 83.980% (8398/10000 100/100 ............]  Step: 31ms | Tot: 286ms | Loss: 0.580 | Acc: 84.400% (844/1000 10/100 ............]  Step: 32ms | Tot: 318ms | Loss: 0.590 | Acc: 84.000% (924/1100 11/10 15/100 88/100 \n",
      "\n",
      "Epoch: 170\n",
      " [=====================================================================================>]  Step: 146ms | Tot: 59s608ms | Loss: 0.937 | Reg: 0.00000 | Acc: 72.533% (36266/50000 391/391 \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s637ms | Loss: 0.600 | Acc: 83.450% (8345/10000 100/100 \n",
      "\n",
      "Epoch: 171\n",
      " [=====================================================================================>]  Step: 155ms | Tot: 59s620ms | Loss: 0.935 | Reg: 0.00000 | Acc: 72.941% (36470/50000 391/391 \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s893ms | Loss: 0.576 | Acc: 83.320% (8332/10000 100/100 .........]  Step: 45ms | Tot: 3s298ms | Loss: 0.578 | Acc: 83.200% (7072/8500 85/100 =============================================================>............]  Step: 33ms | Tot: 3s376ms | Loss: 0.578 | Acc: 83.207% (7239/8700 87/100 ===========================>..]  Step: 46ms | Tot: 3s817ms | Loss: 0.577 | Acc: 83.306% (8164/9800 98/100 \n",
      "\n",
      "Epoch: 172\n",
      " [=====================================================================================>]  Step: 170ms | Tot: 1m737ms | Loss: 0.920 | Reg: 0.00000 | Acc: 73.517% (36758/50000 391/391  \n",
      " [=====================================================================================>]  Step: 31ms | Tot: 3s616ms | Loss: 0.585 | Acc: 82.890% (8289/10000 100/100 ............................................................]  Step: 32ms | Tot: 611ms | Loss: 0.568 | Acc: 83.833% (1509/1800 18/10 26/100 ...]  Step: 44ms | Tot: 962ms | Loss: 0.581 | Acc: 83.111% (2244/2700 27/10 61/10 62/100 ==============================>..........................]  Step: 31ms | Tot: 2s488ms | Loss: 0.591 | Acc: 82.586% (5781/7000 70/100 >......]  Step: 40ms | Tot: 3s391ms | Loss: 0.587 | Acc: 82.777% (7781/9400 94/100 \n",
      "\n",
      "Epoch: 173\n",
      " [=====================================================================================>]  Step: 380ms | Tot: 1m1s | Loss: 0.908 | Reg: 0.00000 | Acc: 74.218% (37109/50000 391/391 91  \n",
      " [=====================================================================================>]  Step: 34ms | Tot: 3s702ms | Loss: 0.593 | Acc: 83.070% (8307/10000 100/100 .........................................................]  Step: 38ms | Tot: 202ms | Loss: 0.560 | Acc: 84.286% (590/700 7/10 18/10 19/100 21/10 22/10 48/100 ...]  Step: 38ms | Tot: 1s742ms | Loss: 0.590 | Acc: 83.510% (4092/4900 49/100 84/100 87/10 88/100 92/10 98/100 \n",
      "\n",
      "Epoch: 174\n",
      " [=====================================================================================>]  Step: 161ms | Tot: 1m143ms | Loss: 0.933 | Reg: 0.00000 | Acc: 72.808% (36403/50000 391/391  \n",
      " [=====================================================================================>]  Step: 38ms | Tot: 3s883ms | Loss: 0.602 | Acc: 84.080% (8408/10000 100/100 100 ........]  Step: 41ms | Tot: 1s616ms | Loss: 0.607 | Acc: 84.077% (3279/3900 39/100 .......]  Step: 27ms | Tot: 1s958ms | Loss: 0.602 | Acc: 84.245% (4128/4900 49/10 50/10 51/10 61/100 >.................................]  Step: 36ms | Tot: 2s433ms | Loss: 0.603 | Acc: 83.952% (5205/6200 62/100 63/100 65/100 ...............]  Step: 42ms | Tot: 2s786ms | Loss: 0.609 | Acc: 83.676% (5941/7100 71/100 90/100 ============>..]  Step: 42ms | Tot: 3s798ms | Loss: 0.603 | Acc: 84.041% (8236/9800 98/100 \n",
      "\n",
      "Epoch: 175\n",
      " [=====================================================================================>]  Step: 153ms | Tot: 1m873ms | Loss: 0.928 | Reg: 0.00000 | Acc: 73.096% (36547/50000 391/391  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [=====================================================================================>]  Step: 35ms | Tot: 3s705ms | Loss: 0.594 | Acc: 83.320% (8332/10000 100/100 ...............................]  Step: 37ms | Tot: 808ms | Loss: 0.585 | Acc: 83.913% (1930/2300 23/100 37/10 38/100 41/100 ======>.]  Step: 38ms | Tot: 3s670ms | Loss: 0.594 | Acc: 83.313% (8248/9900 99/100 \n",
      "\n",
      "Epoch: 176\n",
      " [=====================================================================================>]  Step: 370ms | Tot: 1m443ms | Loss: 0.916 | Reg: 0.00000 | Acc: 73.886% (36943/50000 391/391  \n",
      " [=====================================================================================>]  Step: 35ms | Tot: 3s680ms | Loss: 0.598 | Acc: 84.070% (8407/10000 100/100 .....................................................]  Step: 42ms | Tot: 1s281ms | Loss: 0.603 | Acc: 83.914% (2937/3500 35/100 ................]  Step: 40ms | Tot: 2s502ms | Loss: 0.599 | Acc: 83.985% (5711/6800 68/100 74/100 =============================>........]  Step: 37ms | Tot: 3s328ms | Loss: 0.599 | Acc: 83.912% (7636/9100 91/100 95/100 ===>....]  Step: 40ms | Tot: 3s528ms | Loss: 0.600 | Acc: 83.969% (8061/9600 96/100 \n",
      "\n",
      "Epoch: 177\n",
      " [=====================================================================================>]  Step: 166ms | Tot: 1m673ms | Loss: 0.914 | Reg: 0.00000 | Acc: 73.432% (36715/50000 391/391  \n",
      " [=====================================================================================>]  Step: 33ms | Tot: 3s926ms | Loss: 0.595 | Acc: 83.520% (8352/10000 100/100 0 15/100 ======>.......................................]  Step: 45ms | Tot: 2s217ms | Loss: 0.596 | Acc: 83.636% (4600/5500 55/100 56/100 ............]  Step: 42ms | Tot: 2s414ms | Loss: 0.595 | Acc: 83.567% (5014/6000 60/100 ==>.......................]  Step: 26ms | Tot: 2s921ms | Loss: 0.599 | Acc: 83.378% (6170/7400 74/100 ..............]  Step: 40ms | Tot: 2s992ms | Loss: 0.598 | Acc: 83.461% (6343/7600 76/100 =========================>.................]  Step: 41ms | Tot: 3s187ms | Loss: 0.598 | Acc: 83.383% (6754/8100 81/100 82/100 ......]  Step: 38ms | Tot: 3s265ms | Loss: 0.597 | Acc: 83.410% (6923/8300 83/100 ====>..]  Step: 40ms | Tot: 3s850ms | Loss: 0.596 | Acc: 83.500% (8183/9800 98/100 \n",
      "\n",
      "Epoch: 178\n",
      " [=====================================================================================>]  Step: 367ms | Tot: 1m686ms | Loss: 0.926 | Reg: 0.00000 | Acc: 73.189% (36594/50000 391/391  \n",
      " [=====================================================================================>]  Step: 41ms | Tot: 3s663ms | Loss: 0.585 | Acc: 83.070% (8307/10000 100/100 00 ...]  Step: 39ms | Tot: 2s846ms | Loss: 0.589 | Acc: 82.937% (6552/7900 79/100 ...]  Step: 39ms | Tot: 2s885ms | Loss: 0.590 | Acc: 82.963% (6637/8000 80/10 92/100 ===========================================>......]  Step: 42ms | Tot: 3s379ms | Loss: 0.587 | Acc: 82.957% (7715/9300 93/100 \n",
      "\n",
      "Epoch: 179\n",
      " [=====================================================================================>]  Step: 159ms | Tot: 1m967ms | Loss: 0.953 | Reg: 0.00000 | Acc: 72.487% (36243/50000 391/391  \n",
      " [=====================================================================================>]  Step: 35ms | Tot: 3s572ms | Loss: 0.594 | Acc: 83.220% (8322/10000 100/100 0 ................]  Step: 40ms | Tot: 1s93ms | Loss: 0.593 | Acc: 83.194% (2579/3100 31/100 ....]  Step: 40ms | Tot: 2s156ms | Loss: 0.596 | Acc: 83.183% (4991/6000 60/10 74/10 79/100 85/100 .]  Step: 32ms | Tot: 3s33ms | Loss: 0.598 | Acc: 82.965% (7135/8600 86/100 =============>....]  Step: 41ms | Tot: 3s423ms | Loss: 0.597 | Acc: 83.052% (7973/9600 96/100 \n",
      "\n",
      "Epoch: 180\n",
      " [=====================================================================================>]  Step: 150ms | Tot: 1m778ms | Loss: 0.928 | Reg: 0.00000 | Acc: 73.081% (36540/50000 391/391  \n",
      " [=====================================================================================>]  Step: 43ms | Tot: 3s739ms | Loss: 0.605 | Acc: 82.550% (8255/10000 100/100 ........]  Step: 41ms | Tot: 812ms | Loss: 0.595 | Acc: 82.870% (1906/2300 23/100 ....................]  Step: 42ms | Tot: 930ms | Loss: 0.605 | Acc: 82.462% (2144/2600 26/100 .............]  Step: 40ms | Tot: 1s682ms | Loss: 0.603 | Acc: 82.644% (3719/4500 45/100 87/10 89/100 ========================================================================>........]  Step: 33ms | Tot: 3s379ms | Loss: 0.606 | Acc: 82.396% (7498/9100 91/10 94/100 >..]  Step: 41ms | Tot: 3s659ms | Loss: 0.606 | Acc: 82.531% (8088/9800 98/100 \n",
      "\n",
      "Epoch: 181\n",
      " [=====================================================================================>]  Step: 149ms | Tot: 59s277ms | Loss: 0.944 | Reg: 0.00000 | Acc: 72.340% (36170/50000 391/391 \n",
      " [=====================================================================================>]  Step: 35ms | Tot: 3s601ms | Loss: 0.589 | Acc: 83.760% (8376/10000 100/100 \n",
      "\n",
      "Epoch: 182\n",
      " [=====================================================================================>]  Step: 148ms | Tot: 59s163ms | Loss: 0.939 | Reg: 0.00000 | Acc: 72.648% (36324/50000 391/391 \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s670ms | Loss: 0.599 | Acc: 82.660% (8266/10000 100/100 \n",
      "\n",
      "Epoch: 183\n",
      " [=====================================================================================>]  Step: 140ms | Tot: 58s698ms | Loss: 0.908 | Reg: 0.00000 | Acc: 73.881% (36940/50000 391/391 \n",
      " [=====================================================================================>]  Step: 37ms | Tot: 3s622ms | Loss: 0.606 | Acc: 83.300% (8330/10000 100/100 \n",
      "\n",
      "Epoch: 184\n",
      " [=====================================================================================>]  Step: 151ms | Tot: 59s35ms | Loss: 0.909 | Reg: 0.00000 | Acc: 73.696% (36847/50000 391/391  \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s667ms | Loss: 0.576 | Acc: 83.760% (8376/10000 100/100 \n",
      "\n",
      "Epoch: 185\n",
      " [=====================================================================================>]  Step: 153ms | Tot: 58s862ms | Loss: 0.967 | Reg: 0.00000 | Acc: 71.411% (35705/50000 391/391 \n",
      " [=====================================================================================>]  Step: 38ms | Tot: 3s671ms | Loss: 0.610 | Acc: 82.380% (8238/10000 100/100 \n",
      "\n",
      "Epoch: 186\n",
      " [=====================================================================================>]  Step: 149ms | Tot: 59s287ms | Loss: 0.947 | Reg: 0.00000 | Acc: 72.699% (36349/50000 391/391 \n",
      " [=====================================================================================>]  Step: 39ms | Tot: 3s687ms | Loss: 0.596 | Acc: 83.420% (8342/10000 100/100 Step: 46ms | Tot: 1s8ms | Loss: 0.592 | Acc: 83.429% (2336/2800 28/100 ........................]  Step: 36ms | Tot: 1s45ms | Loss: 0.592 | Acc: 83.448% (2420/2900 29/10 31/100 \n",
      "\n",
      "Epoch: 187\n",
      " [=====================================================================================>]  Step: 152ms | Tot: 59s614ms | Loss: 0.951 | Reg: 0.00000 | Acc: 72.383% (36191/50000 391/391 \n",
      " [=====================================================================================>]  Step: 38ms | Tot: 3s858ms | Loss: 0.591 | Acc: 83.490% (8349/10000 100/100 \n",
      "\n",
      "Epoch: 188\n",
      " [=====================================================================================>]  Step: 153ms | Tot: 59s517ms | Loss: 0.926 | Reg: 0.00000 | Acc: 73.201% (36600/50000 391/391 \n",
      " [=====================================================================================>]  Step: 35ms | Tot: 3s637ms | Loss: 0.606 | Acc: 82.730% (8273/10000 100/100 .................................]  Step: 37ms | Tot: 499ms | Loss: 0.591 | Acc: 83.733% (1256/1500 15/100 68/100 \n",
      "\n",
      "Epoch: 189\n",
      " [=====================================================================================>]  Step: 151ms | Tot: 59s578ms | Loss: 0.979 | Reg: 0.00000 | Acc: 71.315% (35657/50000 391/391 \n",
      " [=====================================================================================>]  Step: 32ms | Tot: 3s697ms | Loss: 0.605 | Acc: 83.160% (8316/10000 100/100 /100 \n",
      "\n",
      "Epoch: 190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [=====================================================================================>]  Step: 136ms | Tot: 1m407ms | Loss: 0.923 | Reg: 0.00000 | Acc: 73.267% (36633/50000 391/391  \n",
      " [=====================================================================================>]  Step: 37ms | Tot: 3s683ms | Loss: 0.607 | Acc: 82.150% (8215/10000 100/100 .................................]  Step: 31ms | Tot: 296ms | Loss: 0.588 | Acc: 83.200% (832/1000 10/100 ..................]  Step: 44ms | Tot: 581ms | Loss: 0.589 | Acc: 83.118% (1413/1700 17/100 ....................................]  Step: 40ms | Tot: 621ms | Loss: 0.593 | Acc: 82.889% (1492/1800 18/100 .......................]  Step: 40ms | Tot: 698ms | Loss: 0.593 | Acc: 83.250% (1665/2000 20/100 ]  Step: 43ms | Tot: 3s197ms | Loss: 0.609 | Acc: 81.966% (7213/8800 88/100 \n",
      "\n",
      "Epoch: 191\n",
      " [=====================================================================================>]  Step: 160ms | Tot: 1m1s | Loss: 0.951 | Reg: 0.00000 | Acc: 72.069% (36034/50000 391/391 91  \n",
      " [=====================================================================================>]  Step: 41ms | Tot: 3s690ms | Loss: 0.591 | Acc: 83.240% (8324/10000 100/100 00 23/100 ======================================>...............................................]  Step: 38ms | Tot: 1s643ms | Loss: 0.588 | Acc: 83.500% (3841/4600 46/100 ==============>.................................]  Step: 41ms | Tot: 2s225ms | Loss: 0.592 | Acc: 83.081% (5151/6200 62/100 63/100 ============================================>...............................]  Step: 41ms | Tot: 2s303ms | Loss: 0.591 | Acc: 83.125% (5320/6400 64/10 85/100 .......]  Step: 41ms | Tot: 3s135ms | Loss: 0.594 | Acc: 82.977% (7136/8600 86/100 =>............]  Step: 39ms | Tot: 3s174ms | Loss: 0.593 | Acc: 83.069% (7227/8700 87/100 ===================================>......]  Step: 42ms | Tot: 3s413ms | Loss: 0.593 | Acc: 83.118% (7730/9300 93/100 =================================================================>....]  Step: 40ms | Tot: 3s530ms | Loss: 0.594 | Acc: 83.094% (7977/9600 96/100 ===========>..]  Step: 41ms | Tot: 3s611ms | Loss: 0.592 | Acc: 83.194% (8153/9800 98/100 \n",
      "\n",
      "Epoch: 192\n",
      " [=====================================================================================>]  Step: 159ms | Tot: 1m1s | Loss: 0.929 | Reg: 0.00000 | Acc: 73.293% (36646/50000 391/391 91  \n",
      " [=====================================================================================>]  Step: 39ms | Tot: 3s726ms | Loss: 0.584 | Acc: 83.230% (8323/10000 100/100 ...]  Step: 42ms | Tot: 1s170ms | Loss: 0.576 | Acc: 83.515% (2756/3300 33/100  43/100 ==========================================>..........]  Step: 40ms | Tot: 3s284ms | Loss: 0.584 | Acc: 83.067% (7393/8900 89/100 ===============================================================>......]  Step: 42ms | Tot: 3s487ms | Loss: 0.585 | Acc: 83.117% (7813/9400 94/100 ====>....]  Step: 44ms | Tot: 3s570ms | Loss: 0.586 | Acc: 83.115% (7979/9600 96/100 =============>..]  Step: 41ms | Tot: 3s646ms | Loss: 0.585 | Acc: 83.194% (8153/9800 98/100 \n",
      "\n",
      "Epoch: 193\n",
      " [=====================================================================================>]  Step: 157ms | Tot: 1m1s | Loss: 0.946 | Reg: 0.00000 | Acc: 72.296% (36148/50000 391/391 91  \n",
      " [=====================================================================================>]  Step: 35ms | Tot: 3s741ms | Loss: 0.591 | Acc: 83.070% (8307/1000 99/100  ....]  Step: 44ms | Tot: 1s272ms | Loss: 0.592 | Acc: 82.972% (2987/3600 36/100 38/100 .............]  Step: 41ms | Tot: 1s388ms | Loss: 0.596 | Acc: 83.128% (3242/3900 39/100 ...........]  Step: 41ms | Tot: 1s430ms | Loss: 0.595 | Acc: 83.150% (3326/4000 40/10 46/100 ......................]  Step: 39ms | Tot: 1s693ms | Loss: 0.591 | Acc: 83.149% (3908/4700 47/100 ..............]  Step: 43ms | Tot: 1s736ms | Loss: 0.592 | Acc: 83.125% (3990/4800 48/100 ]  Step: 38ms | Tot: 2s380ms | Loss: 0.592 | Acc: 82.923% (5390/6500 65/100 ...........]  Step: 41ms | Tot: 3s178ms | Loss: 0.595 | Acc: 82.837% (7124/8600 86/100 ================>.........]  Step: 40ms | Tot: 3s339ms | Loss: 0.594 | Acc: 82.889% (7460/9000 90/100 =====================>....]  Step: 40ms | Tot: 3s583ms | Loss: 0.594 | Acc: 82.958% (7964/9600 96/100 100/100 \n",
      "\n",
      "Epoch: 194\n",
      " [=====================================================================================>]  Step: 167ms | Tot: 1m1s | Loss: 0.954 | Reg: 0.00000 | Acc: 71.833% (35916/50000 391/391 91  \n",
      " [=====================================================================================>]  Step: 38ms | Tot: 3s722ms | Loss: 0.600 | Acc: 83.520% (8352/1000098/100 ..........]  Step: 43ms | Tot: 686ms | Loss: 0.588 | Acc: 84.550% (1691/2000 20/10 21/10 22/100 ...............................]  Step: 40ms | Tot: 923ms | Loss: 0.599 | Acc: 83.423% (2169/2600 26/100 .............................]  Step: 45ms | Tot: 1s347ms | Loss: 0.604 | Acc: 83.622% (3094/3700 37/10 89/100 ==========================================>.......]  Step: 41ms | Tot: 3s417ms | Loss: 0.601 | Acc: 83.435% (7676/9200 92/100 ==>......]  Step: 39ms | Tot: 3s457ms | Loss: 0.601 | Acc: 83.419% (7758/9300 93/100 99/10 100/100 \n",
      "\n",
      "Epoch: 195\n",
      " [=====================================================================================>]  Step: 155ms | Tot: 1m1s | Loss: 0.916 | Reg: 0.00000 | Acc: 73.589% (36794/50000 391/391 91  \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s685ms | Loss: 0.598 | Acc: 83.260% (8326/10000 100/100 .........................................]  Step: 36ms | Tot: 544ms | Loss: 0.583 | Acc: 84.062% (1345/1600 16/100 17/100 ................................................................]  Step: 32ms | Tot: 709ms | Loss: 0.586 | Acc: 83.857% (1761/2100 21/100 ...........]  Step: 42ms | Tot: 2s154ms | Loss: 0.599 | Acc: 83.167% (4990/6000 60/100 .......................]  Step: 43ms | Tot: 2s392ms | Loss: 0.597 | Acc: 83.136% (5487/6600 66/100 ]  Step: 44ms | Tot: 2s505ms | Loss: 0.602 | Acc: 82.928% (5722/6900 69/10 70/100 ====>..........]  Step: 40ms | Tot: 3s252ms | Loss: 0.600 | Acc: 83.067% (7393/8900 89/100 =>...]  Step: 42ms | Tot: 3s572ms | Loss: 0.600 | Acc: 83.155% (8066/9700 97/100 \n",
      "\n",
      "Epoch: 196\n",
      " [=====================================================================================>]  Step: 156ms | Tot: 1m671ms | Loss: 0.938 | Reg: 0.00000 | Acc: 72.902% (36450/50000 391/391  \n",
      " [=====================================================================================>]  Step: 37ms | Tot: 3s671ms | Loss: 0.616 | Acc: 81.660% (8166/10000 100/100 ]  Step: 40ms | Tot: 403ms | Loss: 0.606 | Acc: 82.583% (991/1200 12/10 36/100 ========>.......................................................]  Step: 35ms | Tot: 1s304ms | Loss: 0.622 | Acc: 81.541% (3017/3700 37/100 ===========================>......................................................]  Step: 32ms | Tot: 1s336ms | Loss: 0.624 | Acc: 81.500% (3097/3800 38/100 =>.................................................]  Step: 39ms | Tot: 1s535ms | Loss: 0.618 | Acc: 81.721% (3514/4300 43/100 75/100 ............]  Step: 39ms | Tot: 3s31ms | Loss: 0.619 | Acc: 81.369% (6835/8400 84/100 ..........]  Step: 35ms | Tot: 3s66ms | Loss: 0.619 | Acc: 81.412% (6920/8500 85/100 86/100  89/100 ...]  Step: 39ms | Tot: 3s262ms | Loss: 0.619 | Acc: 81.411% (7327/9000 90/100 ======>........]  Step: 39ms | Tot: 3s302ms | Loss: 0.618 | Acc: 81.451% (7412/9100 91/10 94/100 ========================================================================>.....]  Step: 43ms | Tot: 3s465ms | Loss: 0.618 | Acc: 81.547% (7747/9500 95/100 ==============================================================>....]  Step: 42ms | Tot: 3s507ms | Loss: 0.619 | Acc: 81.510% (7825/9600 96/100 \n",
      "\n",
      "Epoch: 197\n",
      " [=====================================================================================>]  Step: 166ms | Tot: 1m517ms | Loss: 0.959 | Reg: 0.00000 | Acc: 71.574% (35786/50000 391/391  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [=====================================================================================>]  Step: 31ms | Tot: 3s609ms | Loss: 0.601 | Acc: 83.350% (8335/10000 100/100 0 ...........]  Step: 38ms | Tot: 521ms | Loss: 0.588 | Acc: 84.312% (1349/1600 16/100 ..........................]  Step: 40ms | Tot: 1s962ms | Loss: 0.605 | Acc: 83.393% (4670/5600 56/100 ========>..........]  Step: 43ms | Tot: 3s197ms | Loss: 0.603 | Acc: 83.236% (7408/8900 89/100 ====================================================================>.........]  Step: 33ms | Tot: 3s231ms | Loss: 0.603 | Acc: 83.200% (7488/9000 90/100 96/100 ====================>...]  Step: 41ms | Tot: 3s500ms | Loss: 0.603 | Acc: 83.268% (8077/9700 97/10 99/100 \n",
      "\n",
      "Epoch: 198\n",
      " [=====================================================================================>]  Step: 156ms | Tot: 1m218ms | Loss: 0.947 | Reg: 0.00000 | Acc: 72.408% (36204/50000 391/391  \n",
      " [=====================================================================================>]  Step: 37ms | Tot: 3s614ms | Loss: 0.610 | Acc: 82.620% (8262/10000 100/100 ..]  Step: 38ms | Tot: 1s509ms | Loss: 0.612 | Acc: 82.795% (3643/4400 44/100 76/100 =>.........]  Step: 40ms | Tot: 3s224ms | Loss: 0.612 | Acc: 82.422% (7418/9000 90/100 93/100 96/100 ]  Step: 43ms | Tot: 3s503ms | Loss: 0.612 | Acc: 82.515% (8004/9700 97/100 \n",
      "\n",
      "Epoch: 199\n",
      " [=====================================================================================>]  Step: 152ms | Tot: 59s818ms | Loss: 0.898 | Reg: 0.00000 | Acc: 74.307% (37153/50000 391/391 \n",
      " [=====================================================================================>]  Step: 36ms | Tot: 3s627ms | Loss: 0.612 | Acc: 82.880% (8288/10000 100/100 \n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(logname):\n",
    "    with open(logname, 'w') as logfile:\n",
    "        logwriter = csv.writer(logfile, delimiter=',')\n",
    "        logwriter.writerow(['epoch', 'train loss', 'reg loss', 'train acc',\n",
    "                            'test loss', 'test acc'])\n",
    "\n",
    "for epoch in range(start_epoch, params[\"epoch\"]):\n",
    "    train_loss, reg_loss, train_acc = train(epoch, erm=False, advs_train=True, epsilon=.45)\n",
    "    test_loss, test_acc = test(epoch)\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    with open(logname, 'a') as logfile:\n",
    "        logwriter = csv.writer(logfile, delimiter=',')\n",
    "        logwriter.writerow([epoch, train_loss, reg_loss, train_acc, test_loss,\n",
    "                            test_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "quality-vector",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9240, 0.8982, 0.8241, 0.9473, 0.9188, 0.9969, 0.8158, 0.9043, 0.9454,\n",
      "        0.8998]) tensor([1, 5, 2, 9, 9, 9, 3, 1, 2, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[False, False,  True, False, False, False, False, False, False, False]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.eval()\n",
    "out = net(trainset[0][0].reshape(1,3,32,32))\n",
    "out = torch.rand(10,10)\n",
    "a,b = torch.max(out.cpu().data, 1)\n",
    "print(a, b)\n",
    "targ = torch.tensor([[9, 4, 2, 3, 5, 1, 2 ,3, 5, 6]])\n",
    "b.eq(targ.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "attempted-plaintiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_robust(epsilon=0):\n",
    "#     net.cuda()\n",
    "#     net.to('cpu')\n",
    "    net.to(f'cuda:{net.device_ids[0]}')\n",
    "    net.eval()\n",
    "    incorrect = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (normal_inpts, targets) in tqdm(enumerate(testloader)):\n",
    "        if use_cuda:\n",
    "            normal_inpts, targets = normal_inpts.cuda(), targets.cuda()\n",
    "#             normal_inpts, targets = normal_inpts.to('cuda:1'), targets.to('cuda:1')\n",
    "#         normal_inpts, targets = Variable(normal_inpts, volatile=True), Variable(targets)\n",
    "        normal_inpts.requires_grad_(True)\n",
    "        \n",
    "        outputs = net(normal_inpts)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            advers_inp = normal_inpts + (epsilon * normal_inpts.grad.sign())\n",
    "            advers_out = net(advers_inp)\n",
    "#             print(advers_out.cpu().data.shape)\n",
    "            normal_out = net(normal_inpts)\n",
    "            _,advs_predicted = torch.max(advers_out.data, 1)\n",
    "            _,normal_predicted = torch.max(normal_out.data, 1)\n",
    "    \n",
    "\n",
    "#         _, advs_predicted = torch.max(advs_predicted.data, 1)\n",
    "        total += targets.size(0)\n",
    "        incorrect += targets.size(0) - advs_predicted.eq(targets.data).sum()\n",
    "    \n",
    "    print(f'incorrects are: {incorrect} \\ntotal is: {total} \\nTop-1 error is {100.*incorrect/total}')\n",
    "        \n",
    "\n",
    "#     acc = 100.*correct/total\n",
    "#     return (test_loss/batch_idx, 100.*correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "regional-petroleum",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:08, 11.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incorrects are: 446 \n",
      "total is: 10000 \n",
      "Top-1 error is 4.460000038146973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_robust(.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "straight-december",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(84.3200)"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "affiliated-campus",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "#     img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "#     plt.imshow(npimg)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "located-forum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(94.6600)"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "comparative-visitor",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true labels is 1 \n",
      " adversaliral predicted is tensor([6]) \n",
      " nomral is predictedtensor([1])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epsilon = .11\n",
    "i = random.randint(0,100)\n",
    "# i = 1\n",
    "\n",
    "\n",
    "normal_inpt = trainset[i][0].reshape(1,3,32,32).cuda()\n",
    "normal_inpt.requires_grad_(True)\n",
    "out = net(normal_inpt)\n",
    "\n",
    "target = torch.tensor([trainset[i][1]]).cuda()\n",
    "\n",
    "loss = criterion(out, target)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "\n",
    "with torch.no_grad():\n",
    "    advers_inp = normal_inpt + (epsilon * normal_inpt.grad.sign())\n",
    "    advers_out = net(advers_inp)\n",
    "    normal_out = net(normal_inpt)\n",
    "    _,advs_predicted = torch.max(advers_out.cpu().data, 1)\n",
    "    _,normal_predicted = torch.max(normal_out.cpu().data, 1)\n",
    "    \n",
    "print(f'true labels is {target.item()} \\n adversaliral predicted is {advs_predicted} \\n nomral is predicted{normal_predicted}')\n",
    "\n",
    "imshow(normal_inpt.cpu().detach().squeeze())\n",
    "imshow(advers_inp.cpu().detach().squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "inclusive-conspiracy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.4291)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# advers_out = net(advers_inp) #+ (epsilon * normal_inpt.grad.sign())\n",
    "# print(advers_out)\n",
    "mx = 100\n",
    "for j in range(1000):\n",
    "    i = random.randint(0,3000)\n",
    "    if torch.min(torch.min(trainset[i][0], -1)[0], -1)[0][0] < mx:\n",
    "        mx = torch.min(torch.min(trainset[i][0], -1)[0], -1)[0][0]\n",
    "mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "sufficient-repository",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train loss</th>\n",
       "      <th>reg loss</th>\n",
       "      <th>train acc</th>\n",
       "      <th>test loss</th>\n",
       "      <th>test acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.854828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tensor(35.1079)</td>\n",
       "      <td>1.217799</td>\n",
       "      <td>tensor(57.0300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.580279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tensor(48.6740)</td>\n",
       "      <td>0.930699</td>\n",
       "      <td>tensor(69.6800)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.464894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tensor(54.0907)</td>\n",
       "      <td>0.964110</td>\n",
       "      <td>tensor(68.2700)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.409389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tensor(56.5027)</td>\n",
       "      <td>0.768147</td>\n",
       "      <td>tensor(76.2700)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.358588</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tensor(58.5401)</td>\n",
       "      <td>0.707272</td>\n",
       "      <td>tensor(78.8900)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195</td>\n",
       "      <td>0.770341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tensor(74.8484)</td>\n",
       "      <td>0.297381</td>\n",
       "      <td>tensor(95.1700)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>196</td>\n",
       "      <td>0.745491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tensor(75.9486)</td>\n",
       "      <td>0.265202</td>\n",
       "      <td>tensor(95.3000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>197</td>\n",
       "      <td>0.749481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tensor(75.8501)</td>\n",
       "      <td>0.252477</td>\n",
       "      <td>tensor(95.4300)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>198</td>\n",
       "      <td>0.763400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tensor(75.3202)</td>\n",
       "      <td>0.269733</td>\n",
       "      <td>tensor(95.2800)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>0.747603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tensor(75.9354)</td>\n",
       "      <td>0.251721</td>\n",
       "      <td>tensor(95.3500)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     epoch  train loss  reg loss        train acc  test loss         test acc\n",
       "0        0    1.854828       0.0  tensor(35.1079)   1.217799  tensor(57.0300)\n",
       "1        1    1.580279       0.0  tensor(48.6740)   0.930699  tensor(69.6800)\n",
       "2        2    1.464894       0.0  tensor(54.0907)   0.964110  tensor(68.2700)\n",
       "3        3    1.409389       0.0  tensor(56.5027)   0.768147  tensor(76.2700)\n",
       "4        4    1.358588       0.0  tensor(58.5401)   0.707272  tensor(78.8900)\n",
       "..     ...         ...       ...              ...        ...              ...\n",
       "195    195    0.770341       0.0  tensor(74.8484)   0.297381  tensor(95.1700)\n",
       "196    196    0.745491       0.0  tensor(75.9486)   0.265202  tensor(95.3000)\n",
       "197    197    0.749481       0.0  tensor(75.8501)   0.252477  tensor(95.4300)\n",
       "198    198    0.763400       0.0  tensor(75.3202)   0.269733  tensor(95.2800)\n",
       "199    199    0.747603       0.0  tensor(75.9354)   0.251721  tensor(95.3500)\n",
       "\n",
       "[200 rows x 6 columns]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"results/log_ResNet_0_0.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "atomic-hacker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9641, 0.0873, 0.3040],\n",
      "         [0.6683, 0.1927, 0.6105],\n",
      "         [0.8455, 0.1752, 0.4758],\n",
      "         [0.6430, 0.3145, 0.5078]],\n",
      "\n",
      "        [[0.1382, 0.6639, 0.0553],\n",
      "         [0.8324, 0.5710, 0.6972],\n",
      "         [0.8507, 0.6525, 0.6409],\n",
      "         [0.6024, 0.1346, 0.0435]],\n",
      "\n",
      "        [[0.5885, 0.2321, 0.8776],\n",
      "         [0.2466, 0.8369, 0.2947],\n",
      "         [0.8890, 0.1531, 0.4535],\n",
      "         [0.0668, 0.7166, 0.5534]]])\n",
      "tensor([[[0.5173, 0.2153, 0.2674],\n",
      "         [0.3898, 0.2423, 0.3679],\n",
      "         [0.4540, 0.2323, 0.3137],\n",
      "         [0.3856, 0.2776, 0.3368]],\n",
      "\n",
      "        [[0.2768, 0.4683, 0.2548],\n",
      "         [0.3783, 0.2913, 0.3304],\n",
      "         [0.3801, 0.3118, 0.3082],\n",
      "         [0.4549, 0.2849, 0.2601]],\n",
      "\n",
      "        [[0.3294, 0.2307, 0.4399],\n",
      "         [0.2595, 0.4682, 0.2723],\n",
      "         [0.4704, 0.2253, 0.3043],\n",
      "         [0.2202, 0.4217, 0.3582]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000]])"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(3,4,3)\n",
    "print(a)\n",
    "sft = torch.nn.Softmax(-1)\n",
    "print(sft(a))\n",
    "sft(a).sum(-1)\n",
    "# torch.exp(sft(a)).sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "tropical-punch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000])"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(torch.tensor([torch.exp(torch.tensor(1.))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-computer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hugging",
   "language": "python",
   "name": "hugging"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
